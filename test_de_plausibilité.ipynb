{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcBwaujqj7wg"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Ce programme a pour but de tester la plausibilité de la prononciation d'un mot telle qu'indiquée sur le Wiktionnaire.\n",
    "\n",
    "Pour ce faire, il parcours itérativement les différents sons (phonemes) d'un mot et essaie les différentes lettres (graphemes) pouvant être utilisées pour écrire le son (grâce à une table de correspondance similaire à https://fr.wiktionary.org/wiki/Annexe:Prononciation/français#Troisième_approche). A chaque essai, il compare ce qu'il obtient avec l'orthographe utilisée dans le Wiktionnaire. Lorsqu'il arrive au même résultat, la prononciation du mot est jugée plausible. A l'inverse, s'il n'arrive pas à transcrire la même orthographe que celle indiquée dans le Wiktionnaire, la prononciation est jugée suspecte.\n",
    "\n",
    "Ce programme peut aussi compter les différentes lettres utilisées pour transcrire un son. Ainsi, s'il est executé sur tous les mots du Wiktionnaire, il peut servir à compter les probabilités de ces lettres pour transcrire un son donné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iczXUEW6x1g"
   },
   "source": [
    "## Données d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zD26Opi6hhPK"
   },
   "outputs": [],
   "source": [
    "# importation des librairies tierces\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# lecture des données d'entrée (ligne contenant un mot du dictionnaire\n",
    "# ainsi que sa prononciation\n",
    "def read_df():\n",
    "\n",
    "  '''Read the input data (i.e. lines containing a Wiktionary word \n",
    "  and its pronunciation) '''\n",
    "  filename = '../wikt_parser/fr_wiktionary_full.csv'\n",
    "  #filename = '../wikt_parser/fr_wiktionary_waves.csv'\n",
    "    \n",
    "  filepath = Path(filename)\n",
    "\n",
    "  url = 'https://fonétik.fr/'\n",
    "  url_filename = url + filename\n",
    "\n",
    "  #print('downloading ', url_filename)\n",
    "  # if file not found locally, then download it\n",
    "  #if not filepath.exists():\n",
    "  #  !wget -N -q {url_filename}\n",
    "\n",
    "  df = pd.read_csv(filename, keep_default_na=False, sep = '\\t')\n",
    "\n",
    "  return df\n",
    "\n",
    "df = read_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "e8LX-nHWXKQg",
    "outputId": "3d969ca8-f285-451a-cf15-4ff81bdd3c6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1523919</th>\n",
       "      <td>’tit</td>\n",
       "      <td>ti</td>\n",
       "      <td>False</td>\n",
       "      <td>adjectif</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523920</th>\n",
       "      <td>’upa’upa</td>\n",
       "      <td>u.pa.u.pa</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523921</th>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523922</th>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523923</th>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot  Prononciation  H_aspiré           Type Audios  Pré_valide  \\\n",
       "1523919      ’tit             ti     False       adjectif     []        True   \n",
       "1523920  ’upa’upa      u.pa.u.pa     False            nom     []        True   \n",
       "1523921         €           ø.ʁo     False        symbole     []       False   \n",
       "1523922         ℁  o bɔ̃ swɛ̃ də     False    préposition     []       False   \n",
       "1523923         ∴      mɔʁ‿o.vaʃ     False  symbole_num=2     []       False   \n",
       "\n",
       "              Warn_code         Warn_label  \n",
       "1523919               -                  -  \n",
       "1523920               -                  -  \n",
       "1523921  err_lower_case  €_as_first_letter  \n",
       "1523922  err_lower_case  ℁_as_first_letter  \n",
       "1523923  err_lower_case  ∴_as_first_letter  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PmidCDRIAwl"
   },
   "outputs": [],
   "source": [
    "# corriger les & mal-formatés s'il y a en\n",
    "df['Mot'] = df['Mot'].str.replace('&amp;', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XIBkXvacY5sH",
    "outputId": "4c4b2df2-7a5a-4fc7-d528-7a2fc982de78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523924"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage du nombre d'échantillons en entrées\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COxsRMd09a1s"
   },
   "outputs": [],
   "source": [
    "df['Plausible'] = '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "fGy2OiKXEkQm",
    "outputId": "d5299641-eec8-4f01-df56-a86be98911eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1373150</th>\n",
       "      <td>surmédicaliserez</td>\n",
       "      <td>syʁ.me.di.ka.li.zə.ʁe</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280430</th>\n",
       "      <td>chemin au limbe</td>\n",
       "      <td>ʃə.mɛ̃ o lɛ̃b</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_too_many_spaces</td>\n",
       "      <td>2_spaces</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722546</th>\n",
       "      <td>illyrianiserez</td>\n",
       "      <td>i.li.ʁja.ni.zə.ʁe</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190231</th>\n",
       "      <td>resuperposerez</td>\n",
       "      <td>ʁə.sy.pɛʁ.po.zə.ʁe</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322320</th>\n",
       "      <td>sex-symbol</td>\n",
       "      <td>sɛksːɛ̃bɔl</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_phonemes</td>\n",
       "      <td>ː</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Mot          Prononciation  H_aspiré           Type  \\\n",
       "1373150  surmédicaliserez  syʁ.me.di.ka.li.zə.ʁe     False  verbe_flexion   \n",
       "280430    chemin au limbe          ʃə.mɛ̃ o lɛ̃b     False            nom   \n",
       "722546     illyrianiserez      i.li.ʁja.ni.zə.ʁe     False  verbe_flexion   \n",
       "1190231    resuperposerez     ʁə.sy.pɛʁ.po.zə.ʁe     False  verbe_flexion   \n",
       "1322320        sex-symbol             sɛksːɛ̃bɔl     False            nom   \n",
       "\n",
       "        Audios  Pré_valide            Warn_code Warn_label Plausible  \n",
       "1373150     []        True                    -          -         ?  \n",
       "280430      []       False  err_too_many_spaces   2_spaces         ?  \n",
       "722546      []        True                    -          -         ?  \n",
       "1190231     []        True                    -          -         ?  \n",
       "1322320     []       False         err_phonemes          ː         ?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage de 5 derniers échantillons\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "su8M2cf-AGNl",
    "outputId": "9b4be442-25bf-4745-e68e-4b23b8bca0c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1286694</th>\n",
       "      <td>résumpte</td>\n",
       "      <td>ʁe.zɔ̃t</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286695</th>\n",
       "      <td>résumpte</td>\n",
       "      <td>ʁe.zɔ̃pt</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot Prononciation  H_aspiré Type Audios  Pré_valide Warn_code  \\\n",
       "1286694  résumpte       ʁe.zɔ̃t     False  nom     []        True         -   \n",
       "1286695  résumpte      ʁe.zɔ̃pt     False  nom     []        True         -   \n",
       "\n",
       "        Warn_label Plausible  \n",
       "1286694          -         ?  \n",
       "1286695          -         ?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Mot=='résumpte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpcCm53fcXVl"
   },
   "source": [
    "## Table de correspondance entre sons et lettres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def read_table_de_correspondance():\n",
    "    df = pd.read_csv(\"table_de_correspondances.csv\")\n",
    "    phonemes2graphemes = {}\n",
    "    for phoneme in df.Phonème.values:\n",
    "        for position in df[df.Phonème == phoneme].Position.values:\n",
    "            for grapheme in df[df.Phonème == phoneme][df.Position == position].Graphème.values:\n",
    "                if phoneme not in phonemes2graphemes.keys():\n",
    "                    phonemes2graphemes[phoneme] = {}\n",
    "                phonemes2graphemes[phoneme][grapheme] = {}\n",
    "            \n",
    "    return phonemes2graphemes\n",
    "\n",
    "phonemes2graphemes = read_table_de_correspondance()\n",
    "\n",
    "def add_keys(phonemes2graphemes):\n",
    "  '''Ajoute des clés ('occurences', 'exemple_1', 'exemple_2', 'exemple_3')\n",
    "   dans le dictionnaire de chaque grapheme de la table phonemes2graphemes.'''\n",
    "\n",
    "  for phoneme in phonemes2graphemes.keys():\n",
    "    #for position in phonemes2graphemes[phoneme].keys():\n",
    "      for grapheme in phonemes2graphemes[phoneme].keys():\n",
    "        phonemes2graphemes[phoneme][grapheme]['occurences'] = 0\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_1'] = ''\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_2'] = ''\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_3'] = ''\n",
    "\n",
    "  return phonemes2graphemes\n",
    "\n",
    "# run add_keys\n",
    "phonemes2graphemes = add_keys(phonemes2graphemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsDUfNANiXDs"
   },
   "source": [
    "## Fonctions de comptage pour statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-r1cTpGHmAso"
   },
   "outputs": [],
   "source": [
    "# fonction de comptage qui incrémente d'une unité le compteur de correspondance\n",
    "# entre un phonème donné et un graphème donné et qui enregistre en exemple \n",
    "# les trois premiers mots dans lequels la correspondance a été trouvé \n",
    "def increment_occurences(phoneme, grapheme, mot, unit_test=False):\n",
    "  \n",
    "  global phonemes2graphemes\n",
    "\n",
    "  # ne pas continuer si l'appel provient d'un test unitaire\n",
    "  if unit_test:\n",
    "    return\n",
    "\n",
    "  phonemes2graphemes[phoneme][grapheme]['occurences']  += 1\n",
    "  if phonemes2graphemes[phoneme][grapheme]['exemple_1']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_1'] = mot\n",
    "  elif phonemes2graphemes[phoneme][grapheme]['exemple_2']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_2'] = mot\n",
    "  elif phonemes2graphemes[phoneme][grapheme]['exemple_3']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_3'] = mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "nNXz97yImhDC",
    "outputId": "8ad76acb-a3d3-4526-b185-a14aa62197e4"
   },
   "outputs": [],
   "source": [
    "# fonction de statistiques qui calcule pour pour chaque position (initiale,\n",
    "# intermédiaire ou finale) le nombre d'occurences de chaque graphème ainsi\n",
    "# que la probabilité de ce graphème.\n",
    "# Les résultats sont insérés dans un DataFrame pandas et dans un fichier CSV.\n",
    "\n",
    "def make_stats():\n",
    "  global phonemes2graphemes\n",
    "\n",
    "  table = []\n",
    "  for phoneme in phonemes2graphemes:\n",
    "      for grapheme in phonemes2graphemes[phoneme].keys():\n",
    "        occurences = phonemes2graphemes[phoneme][grapheme]['occurences']\n",
    "        exemple_1 = phonemes2graphemes[phoneme][grapheme]['exemple_1']\n",
    "        exemple_2 = phonemes2graphemes[phoneme][grapheme]['exemple_2']\n",
    "        exemple_3 = phonemes2graphemes[phoneme][grapheme]['exemple_3']\n",
    "\n",
    "        #print(\"phoneme=%s grapheme=%s occurences=%d\" % (phoneme, grapheme, occurences))\n",
    "        row = { 'phonème': phoneme, 'graphème':grapheme, 'occurences':occurences, 'pourcentage':0.0,\n",
    "               'exemple_1' : exemple_1, 'exemple_2' : exemple_2, 'exemple_3' : exemple_3, }\n",
    "        table.append(row)\n",
    "  dfp = pd.DataFrame.from_dict(table)\n",
    "\n",
    "  for phoneme in dfp['phonème'].unique():\n",
    "      df1 = dfp[dfp['phonème'] == phoneme]\n",
    "\n",
    "      # calculate the sum of used graphemes within each phoneme-position category\n",
    "      sum = 0\n",
    "      for grapheme in df1['graphème'].unique():\n",
    "        row_number = df1.loc[df1.graphème==grapheme].index[0]\n",
    "        occurences = df1.at[row_number, 'occurences']\n",
    "        sum += occurences\n",
    "\n",
    "      # set the pourcentage of each graphemes for each phoneme-position category\n",
    "      if sum != 0:\n",
    "        for grapheme in df1['graphème'].unique():\n",
    "          row_number = df1.loc[df1.graphème==grapheme].index[0]\n",
    "          occurences = df1.at[row_number, 'occurences']\n",
    "          pourcentage = int(occurences/sum*100)/100\n",
    "          dfp.at[row_number, 'pourcentage'] = pourcentage\n",
    "\n",
    "      dfp.to_csv(\"phonemes2graphemes.csv\", index=False)\n",
    "\n",
    "  return dfp\n",
    "\n",
    "_ = make_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1v0fIw3nuU8"
   },
   "source": [
    "## Fonction de test de plausibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeQZ2cWYoCQG"
   },
   "outputs": [],
   "source": [
    "# Fonction récursive tentant de retrouver tout ou partie des graphemes\n",
    "# depuis tout ou partie des phonemes, à l'aide de la table de correspondance\n",
    "# entre les phonemes et les graphemes.\n",
    "\n",
    "def process_graphemes(mot, phonemes, graphemes, \n",
    "                      phoneme_index=0, grapheme_index=0, \n",
    "                      phonemes_hist='', graphemes_hist='', \n",
    "                      unit_test = False, verbose=False,):\n",
    "  \n",
    "  if verbose:\n",
    "    print('')\n",
    "    print('process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], \\\n",
    "    phoneme_index=%d, grapheme_index=%d, \\\n",
    "    phonemes_hist=%s, graphemes_hist=%s)' \n",
    "            % (phonemes, graphemes, phoneme_index, grapheme_index, phonemes_hist, graphemes_hist))\n",
    "\n",
    "  global phonemes2graphemes\n",
    "\n",
    "  if grapheme_index >= len(graphemes):\n",
    "    if ''.join(graphemes_hist) == graphemes and ''.join(phonemes_hist)==phonemes:\n",
    "        if verbose:\n",
    "            print('ended ok')            \n",
    "        return True, phonemes_hist.copy(), graphemes_hist.copy()\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('ended ko')\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "  current_candidate_phonemes = []\n",
    "  for phoneme in phonemes2graphemes:    \n",
    "    if phonemes[phoneme_index:].startswith(phoneme):      \n",
    "      current_candidate_phonemes.append(phoneme)\n",
    "  if len(current_candidate_phonemes) == 0:\n",
    "    return False, phonemes_hist, graphemes_hist\n",
    "  if verbose:\n",
    "    if len(current_candidate_phonemes) > 1:\n",
    "      print(\"### candidate current phonemes=%\", current_candidate_phonemes)\n",
    "\n",
    "  nb_current_candidate_phonemes = 0 \n",
    "\n",
    "  for current_phoneme in current_candidate_phonemes:\n",
    "    if verbose:\n",
    "      print(\"trying candidate current phoneme=%s\" % current_phoneme)\n",
    "    nb_current_candidate_phonemes += 1\n",
    "    next_phoneme = ''\n",
    "\n",
    "    last_graphemes = graphemes[grapheme_index:]\n",
    "    \n",
    "    if verbose:\n",
    "      print('process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], phoneme_index=%d, grapheme_index=%d) current_phoneme:%s' \n",
    "            % (phonemes, graphemes, phoneme_index, grapheme_index, current_phoneme))\n",
    "  \n",
    "    if verbose:\n",
    "      print('current_phoneme:%s' % current_phoneme)\n",
    "    \n",
    "    try:\n",
    "      len(phonemes2graphemes[current_phoneme])\n",
    "    except:\n",
    "      a=1\n",
    "      if current_phoneme == '':\n",
    "        if verbose:\n",
    "          print('wrn: in [[%s]] : phoneme \\\\%s\\\\ does not exist !!!' % (graphemes, current_phoneme))\n",
    "        return True, phonemes_hist, graphemes_hist\n",
    "      else:\n",
    "        print('err: in [[%s]] : phoneme \\\\%s\\\\ does not exist !!!' % (graphemes, current_phoneme))\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "    matching_graphemes_list = []\n",
    "\n",
    "    for current_graphemes in phonemes2graphemes[current_phoneme]:\n",
    "    \n",
    "      if last_graphemes.startswith(current_graphemes):\n",
    "        if verbose:\n",
    "          print('phoneme \\\\%s\\\\ matching graphemes [[%s]] (last_graphemes:[[%s]])' % (current_phoneme, current_graphemes, last_graphemes))\n",
    "        matching_graphemes_list.append(current_graphemes)\n",
    "\n",
    "    if len(matching_graphemes_list) == 0:\n",
    "      if verbose:\n",
    "        print('KO0: phonemes=\\\\%s\\\\ does not match any grapheme !!!' % (phonemes))\n",
    "\n",
    "      if nb_current_candidate_phonemes == len(current_candidate_phonemes):\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "      else:\n",
    "        if verbose:\n",
    "          print('move0 to next candidate phoneme')\n",
    "        continue\n",
    "      \n",
    "    #print('current_phoneme=', current_phoneme)\n",
    "    \n",
    "    ### * ###\n",
    "    if len(matching_graphemes_list) == 0:\n",
    "        if verbose:\n",
    "          print('KO: phoneme \\\\%s\\\\ matches NO grapheme (in word [[%s]])  !!!' % (graphemes, phonemes))\n",
    "        phonemes_hist.pop()\n",
    "        graphemes_hist.pop()\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "    for current_graphemes in matching_graphemes_list:\n",
    "        \n",
    "        phonemes_hist.append(current_phoneme)\n",
    "        graphemes_hist.append(current_graphemes)\n",
    "\n",
    "        if verbose:\n",
    "          print(\"trying2 current_phoneme \\\\%s\\\\ and current_graphemes [[%s]]\" % (current_phoneme, current_graphemes))\n",
    "\n",
    "        ret, phonemes_hist2, graphemes_hist2 = process_graphemes(\n",
    "            mot,\n",
    "            phonemes, \n",
    "            graphemes,\n",
    "            phoneme_index=phoneme_index+len(current_phoneme), \n",
    "            grapheme_index=grapheme_index+len(current_graphemes),\n",
    "            phonemes_hist = phonemes_hist,\n",
    "            graphemes_hist = graphemes_hist,\n",
    "            unit_test = unit_test,\n",
    "            verbose=verbose)           \n",
    "                \n",
    "        # si la concatenation des graphemes trouvées jusqu'ici n'est pas bonne, alors pas bon\n",
    "        if not graphemes.startswith(''.join(graphemes_hist)):\n",
    "            if verbose:\n",
    "                print(''.join(graphemes_hist)+current_graphemes)\n",
    "                print(graphemes)\n",
    "                print('current_graphemes does not match previous findings')\n",
    "            ret = False          \n",
    "                \n",
    "          # si la concatenation des graphemes trouvées jusqu'ici n'est pas bonne, alors pas bon\n",
    "\n",
    "      \n",
    "        if ret == True:\n",
    "          if verbose:\n",
    "            print('phonemes_hist2b:', phonemes_hist2)\n",
    "            print('graphemes_hist2b:', graphemes_hist2)\n",
    "            print(\"current_phoneme \\\\%s\\\\ and current_graphemes [[%s]] : worked ok\" % (current_phoneme, current_graphemes))\n",
    "          \n",
    "          increment_occurences(current_phoneme, current_graphemes, mot, unit_test)\n",
    "          return True, phonemes_hist2, graphemes_hist2\n",
    "    \n",
    "        phonemes_hist.pop()\n",
    "        graphemes_hist.pop()\n",
    "      \n",
    "    # if here LOST\n",
    "    if verbose:\n",
    "          print('LOST2 for current_phoneme \\\\%s\\\\ in process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], phoneme_index=%d, grapheme_index=%d)' \n",
    "                % (current_phoneme, phonemes, graphemes, phoneme_index, grapheme_index))\n",
    "    \n",
    "    if nb_current_candidate_phonemes == len(current_candidate_phonemes):\n",
    "        return False, phonemes_hist2, graphemes_hist2\n",
    "    else:\n",
    "       \n",
    "        if verbose:\n",
    "          print('move2 to next candidate phoneme')\n",
    "        continue\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZlfYwF1opiA"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOS9qKRWzO42"
   },
   "source": [
    "### Exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhYXjOSbo9_I"
   },
   "outputs": [],
   "source": [
    "exemples = [\n",
    "    (\"momie\", \"mɔmi\"),\n",
    "    (\"pookie\", \"puki\"),\n",
    "\n",
    "]\n",
    "\n",
    "for exemple in exemples:\n",
    "    \n",
    "    mot = exemple[0]\n",
    "    graphemes = exemple[0]\n",
    "    phonemes = exemple[1]\n",
    "    \n",
    "    res = process_graphemes(mot, phonemes, graphemes, \n",
    "                            phoneme_index=0, grapheme_index=0, \n",
    "                            phonemes_hist=[], graphemes_hist=[],\n",
    "                            unit_test=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uh0wZe67re4Z"
   },
   "outputs": [],
   "source": [
    "def check_word_pronunciation(mot, phonemes, graphemes, unit_test=False, verbose0=False, verbose1=False, verbose2=False):\n",
    "\n",
    "    res, phonemes2, graphemes2  = process_graphemes(mot, phonemes, graphemes, phoneme_index=0, grapheme_index=0, phonemes_hist=[], graphemes_hist=[], unit_test=unit_test, verbose=verbose2)\n",
    "    prononciation = ''.join(phonemes2)\n",
    "    word = ''.join(graphemes2)\n",
    "    prononciation_ = ','.join(phonemes2)\n",
    "    word_ = ','.join(graphemes2)\n",
    "    if prononciation != phonemes:\n",
    "      if verbose0:\n",
    "        print('[[%s]] \\\\%s\\\\ -> prononciation=\\\\%s\\\\ ' % (mot, phonemes, prononciation ))\n",
    "      return False\n",
    "    elif word != graphemes.replace('-','').replace(' ',''):\n",
    "      if verbose0:\n",
    "        print('[[%s]] != output graphemes=%s' % (mot, word))\n",
    "      return True\n",
    "    else:\n",
    "      if verbose0:\n",
    "        print('%s \\\\%s\\\\ -> %s \\\\%s\\\\' % (mot, prononciation, word_, prononciation_))\n",
    "      return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXWXcxH2xf-A"
   },
   "source": [
    "### Tests de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "4CZD_l1chhQO",
    "outputId": "6b3a727a-dd48-46fc-ff70-7b99fe30cb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acéphalobrache \\asefalɔbʁak\\ -> a,c,é,ph,a,l,o,b,r,a,che \\a,s,e,f,a,l,ɔ,b,ʁ,a,k\\\n",
      "acquaintance \\akwɛ̃tɑ̃s\\ -> a,cq,u,ain,t,an,ce \\a,k,w,ɛ̃,t,ɑ̃,s\\\n",
      "agoua \\aɡwa\\ -> a,g,ou,a \\a,ɡ,w,a\\\n",
      "bêchâmes \\beʃam\\ -> b,ê,ch,â,mes \\b,e,ʃ,a,m\\\n",
      "caouanne \\kawan\\ -> c,a,ou,a,nne \\k,a,w,a,n\\\n",
      "designer \\dizajnœʁ\\ -> d,e,s,i,g,n,e,r \\d,i,z,a,j,n,œ,ʁ\\\n",
      "désembouteillions \\dezɑ̃butɛjɔ̃\\ -> d,é,s,em,b,ou,t,e,illi,ons \\d,e,z,ɑ̃,b,u,t,ɛ,j,ɔ̃\\\n",
      "disjonctés \\diʒɔ̃kte\\ -> d,is,j,on,c,t,és \\d,i,ʒ,ɔ̃,k,t,e\\\n",
      "droitismes \\dʁwatism\\ -> d,r,o,i,t,i,s,mes \\d,ʁ,w,a,t,i,s,m\\\n",
      "élégante \\eleɡɑ̃t\\ -> é,l,é,g,an,te \\e,l,e,ɡ,ɑ̃,t\\\n",
      "enarrhas \\ɑ̃naʁa\\ -> e,n,a,rrh,as \\ɑ̃,n,a,ʁ,a\\\n",
      "enfutailler \\ɑ̃fytɑje\\ -> en,f,u,t,a,ill,er \\ɑ̃,f,y,t,ɑ,j,e\\\n",
      "excaverai \\ɛkskavəʁe\\ -> e,x,c,a,v,e,r,ai \\ɛ,ks,k,a,v,ə,ʁ,e\\\n",
      "exemple \\ɛɡzɑ̃pl\\ -> e,x,em,p,le \\ɛ,ɡz,ɑ̃,p,l\\\n",
      "fashion \\faʃœn\\ -> f,a,sh,io,n \\f,a,ʃ,œ,n\\\n",
      "khartoumisé \\kaʁtumize\\ -> k,ha,r,t,ou,m,i,s,é \\k,a,ʁ,t,u,m,i,z,e\\\n",
      "hauts \\o\\ -> hauts \\o\\\n",
      "hauts-fonds \\ofɔ̃\\ -> hauts,f,onds \\o,f,ɔ̃\\\n",
      "html \\aʃteɛmɛl\\ -> h,t,m,l \\aʃ,te,ɛm,ɛl\\\n",
      "intérêt \\ɛ̃teʁɛ\\ -> in,t,é,r,êt \\ɛ̃,t,e,ʁ,ɛ\\\n",
      "intéressant \\ɛ̃teʁɛsɑ̃\\ -> in,t,é,r,es,s,ant \\ɛ̃,t,e,ʁ,ɛ,s,ɑ̃\\\n",
      "jaïnas \\dʒaina\\ -> j,a,ï,n,as \\dʒ,a,i,n,a\\\n",
      "luxe \\lyks\\ -> l,u,xe \\l,y,ks\\\n",
      "momie \\mɔmi\\ -> m,o,m,ie \\m,ɔ,m,i\\\n",
      "oiseaux \\wazo\\ -> o,i,s,eaux \\w,a,z,o\\\n",
      "ondoyés \\ɔ̃dwaje\\ -> on,d,o,y,és \\ɔ̃,d,w,aj,e\\\n",
      "peopliser \\piplize\\ -> p,eo,p,l,i,s,er \\p,i,p,l,i,z,e\\\n",
      "pookie \\puki\\ -> p,oo,k,ie \\p,u,k,i\\\n",
      "rechaterais \\ʁətʃatəʁɛ\\ -> r,e,c,h,a,t,e,r,ais \\ʁ,ə,t,ʃ,a,t,ə,ʁ,ɛ\\\n",
      "solex \\solɛks\\ -> s,o,l,e,x \\s,o,l,ɛ,ks\\\n",
      "Paris \\paʁi\\ -> p,a,r,is \\p,a,ʁ,i\\\n",
      "VPN \\vepeɛn\\ -> v,p,n \\ve,pe,ɛn\\\n"
     ]
    }
   ],
   "source": [
    "essais = [\n",
    "    (\"acéphalobrache\", \"asefalɔbʁak\"),\n",
    "    (\"acquaintance\",\"akwɛ̃tɑ̃s\"),\n",
    "    (\"agoua\",\"aɡwa\"),\n",
    "    (\"bêchâmes\",\"beʃam\"),\n",
    "    (\"caouanne\",\"kawan\"),\n",
    "    (\"designer\",\"dizajnœʁ\"),\n",
    "    (\"désembouteillions\",\"dezɑ̃butɛjɔ̃\"),\n",
    "    (\"disjonctés\",\"diʒɔ̃kte\"),\n",
    "    (\"droitismes\", \"dʁwatism\"),\n",
    "    (\"élégante\", \"eleɡɑ̃t\"),\n",
    "    (\"enarrhas\", \"ɑ̃naʁa\"),\n",
    "    (\"enfutailler\", \"ɑ̃fytɑje\"),\n",
    "    (\"excaverai\", \"ɛkskavəʁe\"),\n",
    "    (\"exemple\", \"ɛɡzɑ̃pl\"),\n",
    "    (\"fashion\",\"faʃœn\"),\n",
    "    (\"khartoumisé\",\"kaʁtumize\"),\n",
    "    (\"hauts\", \"o\"),\n",
    "    ('hauts-fonds','o.fɔ̃'),\n",
    "    (\"html\", \"aʃteɛmɛl\"), #acronyme\n",
    "    (\"intérêt\", \"ɛ̃teʁɛ\"),\n",
    "    (\"intéressant\",\"ɛ̃teʁɛsɑ̃\"),\n",
    "    (\"jaïnas\",\"dʒaina\"),\n",
    "    (\"luxe\",\"lyks\"),\n",
    "    (\"momie\",\"mɔmi\"),\n",
    "    (\"oiseaux\", \"wazo\"),\n",
    "    (\"ondoyés\", \"ɔ̃dwaje\"),\n",
    "    (\"peopliser\",\"piplize\"),\n",
    "    (\"pookie\", \"puki\"),\n",
    "    (\"rechaterais\", \"ʁətʃatəʁɛ\"),\n",
    "    ('solex', 'solɛks'),\n",
    "    ('Paris', 'pa.ʁi'),\n",
    "    ('VPN', 've.pe.ɛn'),\n",
    "    \n",
    "]\n",
    "\n",
    "for essai in essais:\n",
    "  #check_word_pronunciation(essai[0], essai[1].replace('.',''), essai[0].lower().replace('-',''), unit_test=True, verbose0=True, verbose1=False, verbose2=False)\n",
    "  check_word_pronunciation(essai[0], essai[1].replace('.',''), essai[0].lower().replace('-',''), unit_test=True, verbose0=True, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_E7sUaT5bd2U"
   },
   "source": [
    "### Test en masse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1aSsYCmh3J0R",
    "outputId": "61692a02-e47c-498f-e447-dcc83f2d84fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523924, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "pWuUXTC23K8P",
    "outputId": "6aba893e-bae7-41a9-a89d-8637e495fc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb mots composés:162224\n",
      "nb mots préfixes:426\n",
      "nb mots noms communs:1328684\n",
      "nb mots noms propres:29461\n",
      "nb mots sigles:2018\n",
      "nb mots autres:1111\n",
      "nb mots TOTAL:1525942\n"
     ]
    }
   ],
   "source": [
    "# trier le dataframe (noms communs, acronymes, noms propres, puis restants)\n",
    "# pour des exemples plus significatifs dans les statistiques\n",
    "df_composés = df[df.Mot.str.match('..*?[\\-\\ ].*?.')].copy()\n",
    "print(\"nb mots composés:%d\" % df_composés.shape[0])\n",
    "\n",
    "df_autres_0 = pd.concat([df, df_composés, df_composés]).drop_duplicates(keep=False)\n",
    "df_préfixes = df_autres_0[df_autres_0.Mot.str.startswith('-')].copy()\n",
    "print(\"nb mots préfixes:%d\" % df_préfixes.shape[0])\n",
    "\n",
    "df_autres_1 = pd.concat([df_autres_0, df_préfixes, df_préfixes]).drop_duplicates(keep=False)\n",
    "df_nc = df_autres_1[df_autres_1.Mot.str.islower()].copy()\n",
    "print(\"nb mots noms communs:%d\" % df_nc.shape[0])\n",
    "\n",
    "df_autres_2 = pd.concat([df_autres_1, df_nc, df_nc]).drop_duplicates(keep=False)\n",
    "df_np = df_autres_2[df_autres_2.Mot.str.istitle()].copy()\n",
    "print(\"nb mots noms propres:%d\" % df_np.shape[0])\n",
    "\n",
    "df_autres_3 = pd.concat([df_autres_2, df_np, df_np]).drop_duplicates(keep=False)\n",
    "df_sigles = df_autres_3[df_autres_3.Mot.str.isupper()].copy()\n",
    "print(\"nb mots sigles:%d\" % df_sigles.shape[0])\n",
    "\n",
    "df_autres_4 = pd.concat([df_autres_3, df_sigles, df_sigles]).drop_duplicates(keep=False)\n",
    "print(\"nb mots autres:%d\" % df_autres_4.shape[0])\n",
    "\n",
    "# mettre dans un ordre augmentant les probabilités de succès des noms composés\n",
    "df_new = pd.concat([df_nc, df_sigles, df_np, df_composés, df_préfixes, df_sigles, df_autres_4], ignore_index=True).copy()\n",
    "print(\"nb mots TOTAL:%d\" % df_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "aQ_ek99vrt_y",
    "outputId": "0ec71f7e-8912-4d98-9193-bacf6891c823"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1481757</th>\n",
       "      <td>éSwatini</td>\n",
       "      <td>e.swa.ti.ni</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512941</th>\n",
       "      <td>éqCO₂</td>\n",
       "      <td>e.ki.va.lɑ̃ se.o.dø</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_letters</td>\n",
       "      <td>₂</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523921</th>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523922</th>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523923</th>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot        Prononciation  H_aspiré           Type Audios  \\\n",
       "1481757  éSwatini          e.swa.ti.ni     False     nom propre     []   \n",
       "1512941     éqCO₂  e.ki.va.lɑ̃ se.o.dø     False            nom     []   \n",
       "1523921         €                 ø.ʁo     False        symbole     []   \n",
       "1523922         ℁        o bɔ̃ swɛ̃ də     False    préposition     []   \n",
       "1523923         ∴            mɔʁ‿o.vaʃ     False  symbole_num=2     []   \n",
       "\n",
       "         Pré_valide       Warn_code         Warn_label Plausible  \n",
       "1481757        True               -                  -         ?  \n",
       "1512941       False     err_letters                  ₂         ?  \n",
       "1523921       False  err_lower_case  €_as_first_letter         ?  \n",
       "1523922       False  err_lower_case  ℁_as_first_letter         ?  \n",
       "1523923       False  err_lower_case  ∴_as_first_letter         ?  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_autres_4.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "01jCIjPAhhQp",
    "outputId": "e21472f2-c2e4-443a-e4fc-4e5b78ac271a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1525282, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_new\n",
    "#df2=df2[df2.Mot.str.istitle()] # ne conserver que les mots commençant par une majuscule puis minuscules\n",
    "#df2=df2[df2.Mot.str.islower()] # ne conserver que les mots entièrement en minuscules (i.e. noms communs)\n",
    "#df2=df2[df2.Mot.str.isupper()] # ne conserver que les mots entièrement en majuscules (i.e. acronymes)#\n",
    "#df2=df2[df2.Mot.str.startswith('x')] # ne conserver que les mots noms communs commençant par ...\n",
    "#df2 = pd.concat([df2, df_composés, df_composés]).drop_duplicates(keep=False) # supprimer les mots composés\n",
    "#df2 = df2[~df2.Mot.str.contains(' ')] # exclure les mots contenant un espace\n",
    "#df2 = df2[~df2.Mot.str.contains('-')] # exclure les mots contenant un tiret\n",
    "\n",
    "df2 = df2[~df2.Mot.str.contains('\\.')] # exclure les mots contenant un point\n",
    "df2 = df2[~df2.Mot.str.contains('/')] # exclure les mots contenant un slash (e.g. copier/coller)\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "JOCz6EX3hhQ0",
    "outputId": "2ef3b62b-3112-4ceb-b3c4-49e0e8cb8892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:1, nb_samples:152528, durée:0:00:48.573682\n",
      "batch:2, nb_samples:305056, durée:0:00:46.727685\n",
      "batch:3, nb_samples:457584, durée:0:00:50.289613\n",
      "batch:4, nb_samples:610112, durée:0:00:47.719374\n",
      "batch:5, nb_samples:762640, durée:0:00:47.836048\n",
      "batch:6, nb_samples:915168, durée:0:00:49.594396\n",
      "batch:7, nb_samples:1067696, durée:0:00:49.542236\n",
      "batch:8, nb_samples:1220224, durée:0:00:49.583613\n",
      "batch:9, nb_samples:1372752, durée:0:01:55.214474\n",
      "batch:10, nb_samples:1525280, durée:0:04:33.512505\n",
      "nb_samples: 1525282  durée de processing du dernier batch: 0:00:00.000582\n",
      "samples=1525282, samples_ok=1518325, samples_ko=6957, very_bad=0, ok%=99.54\n"
     ]
    }
   ],
   "source": [
    "nb_samples=0\n",
    "nb_infos_steps=10\n",
    "nb_samples_steps = int(df2.shape[0]/nb_infos_steps)\n",
    "nb_samples_ok=0\n",
    "nb_samples_ko=0\n",
    "nb_very_bad=0\n",
    "nb_batch=0\n",
    "verbose=False\n",
    "indexes_to_forget = []\n",
    "nb_composés = 0\n",
    "nb_composés_directs_found = 0\n",
    "nb_composés_indirects_found = 0\n",
    "\n",
    "t0 = datetime.datetime.now()\n",
    "for index, row in df2.iterrows():\n",
    "\n",
    "    nb_samples += 1\n",
    "    is_ok = False\n",
    "    is_skipped = False\n",
    "        \n",
    "    if nb_samples >= nb_infos_steps and nb_samples % nb_samples_steps == 0:\n",
    "      nb_batch += 1\n",
    "      t1 = datetime.datetime.now()\n",
    "      durée = t1 - t0\n",
    "      print('batch:%d, nb_samples:%d, durée:%s' % (nb_batch, nb_samples, durée))\n",
    "      t0 = t1\n",
    "\n",
    "    mot = row['Mot']\n",
    "    prononciation = row['Prononciation']\n",
    " \n",
    "    is_composé = False\n",
    "    is_composé_direct = False\n",
    "    if ' ' in row['Mot'] or ',' in row['Mot'] or '-' in row['Mot']:\n",
    "      nb_composés += 1     \n",
    "      is_composé = True\n",
    "        \n",
    "    try:\n",
    "      graphemes = row['Mot'].lower().replace(' ', '').replace('-','').replace(',','')\n",
    "      phonemes = prononciation.replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "      is_ok = check_word_pronunciation(mot, phonemes, graphemes, False, False, False, False)\n",
    "          \n",
    "      if is_ok:\n",
    "        if ' ' in row['Mot'] or ',' in row['Mot'] or '-' in row['Mot']:\n",
    "          is_composé_direct = True\n",
    "          nb_composés_directs_found += 1      \n",
    "    \n",
    "    except:\n",
    "      is_ok = False\n",
    "      is_skipped = True \n",
    "      nb_very_bad+=1\n",
    "      # mauvaise lettre ou phoneme, pas la peine d'aller plus loi\n",
    "      # passer au mot suivant\n",
    "\n",
    "    # si la correspondance n'a pas été trouvé, tester si le mot est composé,\n",
    "    # et si oui, tester la correspondance de chaque partie (aka sous-mot)\n",
    "    if not is_ok and not is_skipped:    \n",
    "      graphemes = row['Mot'].lower().replace(',','')\n",
    "      phonemes = prononciation    \n",
    "      separateurs = [' ', '-']\n",
    "      for separateur in separateurs:\n",
    "        if separateur in graphemes[1:-1] :\n",
    "          mots_ = mot.split(separateur)\n",
    "          # si le mot n'est pas un mot composé, l'oubler, et passer à la suite\n",
    "          if len(mots_) <= 1:\n",
    "            continue\n",
    "          for mot_ in mots_:\n",
    "            try:\n",
    "              # récuperer le sous-mot identifiés ainsi que ses différentes prononciations possibles\n",
    "              phonemess_ = df[df.Mot==mot_]['Prononciation'].values\n",
    "              for phonemes_ in phonemess_:\n",
    "                graphemes_ = mot_\n",
    "                phonemes_ = phonemes_.replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "                is_ok_ = check_word_pronunciation(mot_, phonemes_, graphemes_, False, False, False, False)\n",
    "                if is_ok_:\n",
    "                    break                    \n",
    "              if is_ok_ == False:\n",
    "                is_ok = False                \n",
    "              else:\n",
    "                is_ok = True\n",
    "                break\n",
    "            except:\n",
    "              is_ok = False\n",
    "            \n",
    "    if is_ok and is_composé:\n",
    "        if not is_composé_direct:\n",
    "            nb_composés_indirects_found += 1\n",
    "    #if not is_ok and is_composé:\n",
    "    #    print('word=%s \\\\\\\\%s\\\\\\\\'% (mot, prononciation))\n",
    "        \n",
    "    if is_ok:\n",
    "      nb_samples_ok += 1\n",
    "      df2.at[index, 'Plausible']='oui'\n",
    "      indexes_to_forget.append(index)\n",
    "    else:\n",
    "      nb_samples_ko += 1\n",
    "      if verbose:\n",
    "        if row['Type'] != 'verbe_flexion':\n",
    "          print('word=%s \\\\\\\\%s\\\\\\\\'% (mot, prononciation))\n",
    "      df2.at[index, 'Plausible']='non'\n",
    "        \n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "durée = t1 - t0\n",
    "print('nb_samples:', nb_samples, ' durée de processing du dernier batch:', durée)\n",
    "      \n",
    "df2 = df2.drop(indexes_to_forget)\n",
    "\n",
    "if nb_samples > 0:\n",
    "  print('samples=%d, samples_ok=%d, samples_ko=%d, very_bad=%d, ok%%=%.2f' % \\\n",
    "        (nb_samples, nb_samples_ok, nb_samples_ko, nb_very_bad, \\\n",
    "         nb_samples_ok/nb_samples*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_samples: 1292602  durée de processing du dernier batch: 0:00:00.000838\n",
    "#samples=1292602, samples_ok=1279990, samples_ko=12612, very_bad=0 %ok=99.02\n",
    "\n",
    "#samples=1485362, samples_ok=1471019, samples_ko=14343, very_bad=0, ok%=99.03\n",
    "#nb_composés:160151\n",
    "#nb_composés_directs_found:154583\n",
    "#nb_composés_indirects_found:5216\n",
    "#nb_composés_not_found:352\n",
    "\n",
    "#samples=1485362, samples_ok=1468451, samples_ko=16911, very_bad=0, ok%=98.86\n",
    "#nb_composés:160151\n",
    "#nb_composés_directs_found:0\n",
    "#nb_composés_indirects_found:157231\n",
    "#nb_composés_not_found:2920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6X8pia-32RtQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6957"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nombre de mots dont la prononciation est détectée comme non plausible\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFgO0o3H4Srh",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1525757</th>\n",
       "      <td>TADs</td>\n",
       "      <td>te.a.de</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>T_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525801</th>\n",
       "      <td>TikTokeuse</td>\n",
       "      <td>tik.to.kœʁ</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>T_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525847</th>\n",
       "      <td>URNs</td>\n",
       "      <td>y.ɛʁ.ɛn</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>U_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525848</th>\n",
       "      <td>UpM</td>\n",
       "      <td>y.pe.em</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>U_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525859</th>\n",
       "      <td>Vosg’patt</td>\n",
       "      <td>voʒ.pat</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[\"LL-Q150 (fra)-Penegal-Vosg'patt.wav\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>V_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525860</th>\n",
       "      <td>WEIs</td>\n",
       "      <td>ˈwaj ou ˈwɛj</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>W_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525861</th>\n",
       "      <td>Wuchiaping’ien</td>\n",
       "      <td>wu.tʃja.piŋ.jɛ̃</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>W_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525863</th>\n",
       "      <td>XPs</td>\n",
       "      <td>iks.pe</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525865</th>\n",
       "      <td>Xi’an</td>\n",
       "      <td>ʃi.an</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525866</th>\n",
       "      <td>Xi’an</td>\n",
       "      <td>sjan</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525869</th>\n",
       "      <td>YouTubeur</td>\n",
       "      <td>ju.tju.bœʁ</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525871</th>\n",
       "      <td>YouTubeurs</td>\n",
       "      <td>ju.tju.bœʁ</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525874</th>\n",
       "      <td>YouTubeuse</td>\n",
       "      <td>ju.tju.bøz</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525875</th>\n",
       "      <td>YouTubeuses</td>\n",
       "      <td>ju.tju.bøz</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525918</th>\n",
       "      <td>d’Ursel</td>\n",
       "      <td>dyʁs</td>\n",
       "      <td>False</td>\n",
       "      <td>nom de famille</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525934</th>\n",
       "      <td>raï'n'B</td>\n",
       "      <td>ʁaj.ɛn.bi</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_letters</td>\n",
       "      <td>'</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525938</th>\n",
       "      <td>éqCO₂</td>\n",
       "      <td>e.ki.va.lɑ̃ se.o.dø</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_letters</td>\n",
       "      <td>₂</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525939</th>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525940</th>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525941</th>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mot        Prononciation  H_aspiré            Type  \\\n",
       "1525757            TADs              te.a.de     False     nom_flexion   \n",
       "1525801      TikTokeuse           tik.to.kœʁ     False             nom   \n",
       "1525847            URNs              y.ɛʁ.ɛn     False     nom_flexion   \n",
       "1525848             UpM              y.pe.em     False             nom   \n",
       "1525859       Vosg’patt              voʒ.pat     False             nom   \n",
       "1525860            WEIs         ˈwaj ou ˈwɛj     False     nom_flexion   \n",
       "1525861  Wuchiaping’ien      wu.tʃja.piŋ.jɛ̃     False             nom   \n",
       "1525863             XPs               iks.pe     False     nom_flexion   \n",
       "1525865           Xi’an                ʃi.an     False      nom propre   \n",
       "1525866           Xi’an                 sjan     False      nom propre   \n",
       "1525869       YouTubeur           ju.tju.bœʁ     False             nom   \n",
       "1525871      YouTubeurs           ju.tju.bœʁ     False     nom_flexion   \n",
       "1525874      YouTubeuse           ju.tju.bøz     False     nom_flexion   \n",
       "1525875     YouTubeuses           ju.tju.bøz     False     nom_flexion   \n",
       "1525918         d’Ursel                 dyʁs     False  nom de famille   \n",
       "1525934         raï'n'B            ʁaj.ɛn.bi     False             nom   \n",
       "1525938           éqCO₂  e.ki.va.lɑ̃ se.o.dø     False             nom   \n",
       "1525939               €                 ø.ʁo     False         symbole   \n",
       "1525940               ℁        o bɔ̃ swɛ̃ də     False     préposition   \n",
       "1525941               ∴            mɔʁ‿o.vaʃ     False   symbole_num=2   \n",
       "\n",
       "                                          Audios  Pré_valide       Warn_code  \\\n",
       "1525757                                       []       False  err_lower_case   \n",
       "1525801                                       []       False  err_lower_case   \n",
       "1525847                                       []       False  err_lower_case   \n",
       "1525848                                       []       False  err_lower_case   \n",
       "1525859  [\"LL-Q150 (fra)-Penegal-Vosg'patt.wav\"]       False  err_lower_case   \n",
       "1525860                                       []       False  err_lower_case   \n",
       "1525861                                       []       False  err_lower_case   \n",
       "1525863                                       []       False  err_lower_case   \n",
       "1525865                                       []       False  err_lower_case   \n",
       "1525866                                       []       False  err_lower_case   \n",
       "1525869                                       []       False  err_lower_case   \n",
       "1525871                                       []       False  err_lower_case   \n",
       "1525874                                       []       False  err_lower_case   \n",
       "1525875                                       []       False  err_lower_case   \n",
       "1525918                                       []        True               -   \n",
       "1525934                                       []       False     err_letters   \n",
       "1525938                                       []       False     err_letters   \n",
       "1525939                                       []       False  err_lower_case   \n",
       "1525940                                       []       False  err_lower_case   \n",
       "1525941                                       []       False  err_lower_case   \n",
       "\n",
       "                Warn_label Plausible  \n",
       "1525757  T_as_first_letter       non  \n",
       "1525801  T_as_first_letter       non  \n",
       "1525847  U_as_first_letter       non  \n",
       "1525848  U_as_first_letter       non  \n",
       "1525859  V_as_first_letter       non  \n",
       "1525860  W_as_first_letter       non  \n",
       "1525861  W_as_first_letter       non  \n",
       "1525863  X_as_first_letter       non  \n",
       "1525865  X_as_first_letter       non  \n",
       "1525866  X_as_first_letter       non  \n",
       "1525869  Y_as_first_letter       non  \n",
       "1525871  Y_as_first_letter       non  \n",
       "1525874  Y_as_first_letter       non  \n",
       "1525875  Y_as_first_letter       non  \n",
       "1525918                  -       non  \n",
       "1525934                  '       non  \n",
       "1525938                  ₂       non  \n",
       "1525939  €_as_first_letter       non  \n",
       "1525940  ℁_as_first_letter       non  \n",
       "1525941  ∴_as_first_letter       non  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 derniers mot dont la prononciation est détectée comme non plausible\n",
    "df2[df2.Plausible=='non'].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des résultats KO dans fichiers .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kq85BIVx4TCg"
   },
   "outputs": [],
   "source": [
    "# stockage des mots dot les prononciations sont non plausibles dans un fichier CSV\n",
    "df3 = df2.drop(columns=['Audios','H_aspiré','Pré_valide','Plausible'])\n",
    "df3.rename(columns = {'Err_Code':'Warn_Code', 'Err_Label':'Warn_Label'}, inplace = True)\n",
    "df3.to_csv(\"correspondances_non_trouvées.csv\", index=False, quotechar = '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stockage des mots dont les prononciations sont non plausibles \n",
    "df4 = \"'\" + df3.Mot + \"',\"\n",
    "df4.to_csv(\"mots_non_trouvés.csv\", index=False, quotechar = '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kG2E5cw6nfT9"
   },
   "source": [
    "### Test unitaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyMUWuQmd5Lk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNE\n",
      "nɔʁnɔʁɛst\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=0, grapheme_index=0,     phonemes_hist=[], graphemes_hist=[])\n",
      "### candidate current phonemes=% ['n', 'nɔʁ']\n",
      "trying candidate current phoneme=n\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0) current_phoneme:n\n",
      "current_phoneme:n\n",
      "phoneme \\n\\ matching graphemes [[n]] (last_graphemes:[[nne]])\n",
      "phoneme \\n\\ matching graphemes [[nn]] (last_graphemes:[[nne]])\n",
      "phoneme \\n\\ matching graphemes [[nne]] (last_graphemes:[[nne]])\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=1,     phonemes_hist=['n'], graphemes_hist=['n'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=1, grapheme_index=1) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[nn]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=2,     phonemes_hist=['n'], graphemes_hist=['nn'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=1, grapheme_index=2) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[nne]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=3,     phonemes_hist=['n'], graphemes_hist=['nne'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\n\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=nɔʁ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0) current_phoneme:nɔʁ\n",
      "current_phoneme:nɔʁ\n",
      "phoneme \\nɔʁ\\ matching graphemes [[n]] (last_graphemes:[[nne]])\n",
      "trying2 current_phoneme \\nɔʁ\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=3, grapheme_index=1,     phonemes_hist=['nɔʁ'], graphemes_hist=['n'])\n",
      "### candidate current phonemes=% ['n', 'nɔʁ']\n",
      "trying candidate current phoneme=n\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1) current_phoneme:n\n",
      "current_phoneme:n\n",
      "phoneme \\n\\ matching graphemes [[n]] (last_graphemes:[[ne]])\n",
      "phoneme \\n\\ matching graphemes [[ne]] (last_graphemes:[[ne]])\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=4, grapheme_index=2,     phonemes_hist=['nɔʁ', 'n'], graphemes_hist=['n', 'n'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=4, grapheme_index=2) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[ne]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=4, grapheme_index=3,     phonemes_hist=['nɔʁ', 'n'], graphemes_hist=['n', 'ne'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\n\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=nɔʁ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1) current_phoneme:nɔʁ\n",
      "current_phoneme:nɔʁ\n",
      "phoneme \\nɔʁ\\ matching graphemes [[n]] (last_graphemes:[[ne]])\n",
      "trying2 current_phoneme \\nɔʁ\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=6, grapheme_index=2,     phonemes_hist=['nɔʁ', 'nɔʁ'], graphemes_hist=['n', 'n'])\n",
      "### candidate current phonemes=% ['ɛ', 'ɛs', 'ɛst']\n",
      "trying candidate current phoneme=ɛ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛ\n",
      "current_phoneme:ɛ\n",
      "phoneme \\ɛ\\ matching graphemes [[e]] (last_graphemes:[[e]])\n",
      "trying2 current_phoneme \\ɛ\\ and current_graphemes [[e]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=7, grapheme_index=3,     phonemes_hist=['nɔʁ', 'nɔʁ', 'ɛ'], graphemes_hist=['n', 'n', 'e'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\ɛ\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=ɛs\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛs\n",
      "current_phoneme:ɛs\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "move0 to next candidate phoneme\n",
      "trying candidate current phoneme=ɛst\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛst\n",
      "current_phoneme:ɛst\n",
      "phoneme \\ɛst\\ matching graphemes [[e]] (last_graphemes:[[e]])\n",
      "trying2 current_phoneme \\ɛst\\ and current_graphemes [[e]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=9, grapheme_index=3,     phonemes_hist=['nɔʁ', 'nɔʁ', 'ɛst'], graphemes_hist=['n', 'n', 'e'])\n",
      "ended ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\ɛst\\ and current_graphemes [[e]] : worked ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\nɔʁ\\ and current_graphemes [[n]] : worked ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\nɔʁ\\ and current_graphemes [[n]] : worked ok\n",
      "NNE \\nɔʁnɔʁɛst\\ -> n,n,e \\nɔʁ,nɔʁ,ɛst\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mot et prononciation à tester unitairement\n",
    "graphemes_phonemes='SaturneXI,sa.tyʁnɔ̃z'\n",
    "graphemes_phonemes='SMSses,ɛs.ɛm.ɛs'\n",
    "graphemes_phonemes='NNE,nɔʁ nɔ.ʁ‿ɛst'\n",
    "\n",
    "# recharger la table de correspondance si nécessaire\n",
    "reload_table = False\n",
    "if reload_table:\n",
    "    phonemes2graphemes = read_table_de_correspondance()\n",
    "    phonemes2graphemes = add_keys(phonemes2graphemes)\n",
    "\n",
    "strings = graphemes_phonemes.split(',')\n",
    "mot = strings[0]\n",
    "graphemes = mot.lower()\n",
    "phonemes = strings[1].replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "\n",
    "# nettoyage des strings\n",
    "#graphemes = graphemes.replace(' ','')\n",
    "#graphemes = graphemes.replace('-','')\n",
    "#graphemes = graphemes.replace(\"’\",'')\n",
    "phonemes = phonemes.replace(' ','')\n",
    "phonemes = phonemes.replace('\\\\','')\n",
    "phonemes = phonemes.replace('.','')\n",
    "phonemes = phonemes.replace('‿','')\n",
    "phonemes = phonemes.replace('(','')\n",
    "phonemes = phonemes.replace(')','')\n",
    "print(mot)\n",
    "print(phonemes)\n",
    "# test unitaire\n",
    "check_word_pronunciation(mot, phonemes, graphemes, unit_test=True, verbose0=True, verbose1=True, verbose2=True)\n",
    "#check_word_pronunciation(mot, phonemes, graphemes, unit_test=True, verbose0=False, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "th8Jvzrpk342"
   },
   "source": [
    "## Statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2laCDmzlJJO"
   },
   "outputs": [],
   "source": [
    "# Réaliser les comptages tottax statistiques sur les correspondances \n",
    "# précédemment comptées\n",
    "dfp = make_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBkvDJgyOlj4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>s</td>\n",
       "      <td>c’</td>\n",
       "      <td>179</td>\n",
       "      <td>0.00</td>\n",
       "      <td>c’</td>\n",
       "      <td>c’est</td>\n",
       "      <td>c’que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>s</td>\n",
       "      <td>s’</td>\n",
       "      <td>2974</td>\n",
       "      <td>0.00</td>\n",
       "      <td>s’abader</td>\n",
       "      <td>s’abaisser</td>\n",
       "      <td>s’abaisser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>s</td>\n",
       "      <td>ç’</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ç’</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>83651</td>\n",
       "      <td>0.12</td>\n",
       "      <td>abaciste</td>\n",
       "      <td>abacistes</td>\n",
       "      <td>abandogiciel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>s</td>\n",
       "      <td>ç</td>\n",
       "      <td>10867</td>\n",
       "      <td>0.01</td>\n",
       "      <td>accoinçon</td>\n",
       "      <td>accoinçons</td>\n",
       "      <td>agaça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>291936</td>\n",
       "      <td>0.44</td>\n",
       "      <td>aaronisme</td>\n",
       "      <td>aaronismes</td>\n",
       "      <td>aasax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>s</td>\n",
       "      <td>sc</td>\n",
       "      <td>5355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abscise</td>\n",
       "      <td>abscises</td>\n",
       "      <td>abscision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>s</td>\n",
       "      <td>th</td>\n",
       "      <td>135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>chrestomathie</td>\n",
       "      <td>chrestomathies</td>\n",
       "      <td>classpath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>s</td>\n",
       "      <td>x</td>\n",
       "      <td>504</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antisoixantehuitard</td>\n",
       "      <td>antisoixantehuitards</td>\n",
       "      <td>auxerrois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>s</td>\n",
       "      <td>cc</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>accensa</td>\n",
       "      <td>accensai</td>\n",
       "      <td>accensaient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>s</td>\n",
       "      <td>ce</td>\n",
       "      <td>6310</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayance</td>\n",
       "      <td>aberrance</td>\n",
       "      <td>abjuratrice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>s</td>\n",
       "      <td>sç</td>\n",
       "      <td>112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesça</td>\n",
       "      <td>acquiesçable</td>\n",
       "      <td>acquiesçables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>s</td>\n",
       "      <td>se</td>\n",
       "      <td>1879</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaissemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>s</td>\n",
       "      <td>ss</td>\n",
       "      <td>120904</td>\n",
       "      <td>0.18</td>\n",
       "      <td>abadassiez</td>\n",
       "      <td>abadassions</td>\n",
       "      <td>abaissassiez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>s</td>\n",
       "      <td>sse</td>\n",
       "      <td>33159</td>\n",
       "      <td>0.05</td>\n",
       "      <td>abadasse</td>\n",
       "      <td>abaissasse</td>\n",
       "      <td>abalasse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>s</td>\n",
       "      <td>sth</td>\n",
       "      <td>97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatiques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>28322</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abaliénation</td>\n",
       "      <td>abaliénations</td>\n",
       "      <td>abannation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>s</td>\n",
       "      <td>z</td>\n",
       "      <td>453</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>s</td>\n",
       "      <td>cent</td>\n",
       "      <td>421</td>\n",
       "      <td>0.00</td>\n",
       "      <td>agacent</td>\n",
       "      <td>agencent</td>\n",
       "      <td>agoucent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>s</td>\n",
       "      <td>ces</td>\n",
       "      <td>3365</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayances</td>\n",
       "      <td>aberrances</td>\n",
       "      <td>abjuratrices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>s</td>\n",
       "      <td>sce</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesce</td>\n",
       "      <td>acquiescemens</td>\n",
       "      <td>acquiescement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>s</td>\n",
       "      <td>scent</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiescent</td>\n",
       "      <td>concupiscent</td>\n",
       "      <td>fascent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>s</td>\n",
       "      <td>sces</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesces</td>\n",
       "      <td>concupisces</td>\n",
       "      <td>drosces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>s</td>\n",
       "      <td>sent</td>\n",
       "      <td>355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaissent</td>\n",
       "      <td>absconsent</td>\n",
       "      <td>accensent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>s</td>\n",
       "      <td>ses</td>\n",
       "      <td>1110</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abbesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>s</td>\n",
       "      <td>ssent</td>\n",
       "      <td>29948</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadassent</td>\n",
       "      <td>abaissassent</td>\n",
       "      <td>abalassent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>s</td>\n",
       "      <td>sses</td>\n",
       "      <td>30369</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadasses</td>\n",
       "      <td>abaissasses</td>\n",
       "      <td>abalasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>s</td>\n",
       "      <td>ths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>classpaths</td>\n",
       "      <td>smithsonites</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>s</td>\n",
       "      <td>tz</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anetziens</td>\n",
       "      <td>trénitz</td>\n",
       "      <td>Anetz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage            exemple_1  \\\n",
       "249       s       c’         179         0.00                   c’   \n",
       "250       s       s’        2974         0.00             s’abader   \n",
       "251       s       ç’           1         0.00                   ç’   \n",
       "252       s        c       83651         0.12             abaciste   \n",
       "253       s        ç       10867         0.01            accoinçon   \n",
       "254       s        s      291936         0.44            aaronisme   \n",
       "255       s       sc        5355         0.00              abscise   \n",
       "256       s       th         135         0.00        chrestomathie   \n",
       "257       s        x         504         0.00  antisoixantehuitard   \n",
       "258       s       cc          52         0.00              accensa   \n",
       "259       s       ce        6310         0.00             abayance   \n",
       "260       s       sç         112         0.00            acquiesça   \n",
       "261       s       se        1879         0.00              abaisse   \n",
       "262       s       ss      120904         0.18           abadassiez   \n",
       "263       s      sse       33159         0.05             abadasse   \n",
       "264       s      sth          97         0.00      antiasthmatique   \n",
       "265       s        t       28322         0.04         abaliénation   \n",
       "266       s        z         453         0.00            abertzale   \n",
       "267       s     cent         421         0.00              agacent   \n",
       "268       s      ces        3365         0.00            abayances   \n",
       "269       s      sce          16         0.00            acquiesce   \n",
       "270       s    scent           7         0.00          acquiescent   \n",
       "271       s     sces          10         0.00           acquiesces   \n",
       "272       s     sent         355         0.00            abaissent   \n",
       "273       s      ses        1110         0.00             abaisses   \n",
       "274       s    ssent       29948         0.04           abadassent   \n",
       "275       s     sses       30369         0.04            abadasses   \n",
       "276       s      ths           2         0.00           classpaths   \n",
       "277       s       tz          12         0.00            anetziens   \n",
       "\n",
       "                exemple_2         exemple_3  \n",
       "249                 c’est             c’que  \n",
       "250            s’abaisser        s’abaisser  \n",
       "251                                          \n",
       "252             abacistes      abandogiciel  \n",
       "253            accoinçons             agaça  \n",
       "254            aaronismes             aasax  \n",
       "255              abscises         abscision  \n",
       "256        chrestomathies         classpath  \n",
       "257  antisoixantehuitards         auxerrois  \n",
       "258              accensai       accensaient  \n",
       "259             aberrance       abjuratrice  \n",
       "260          acquiesçable     acquiesçables  \n",
       "261               abaisse       abaissemens  \n",
       "262           abadassions      abaissassiez  \n",
       "263            abaissasse          abalasse  \n",
       "264       antiasthmatique  antiasthmatiques  \n",
       "265         abaliénations        abannation  \n",
       "266             abertzale        abertzales  \n",
       "267              agencent          agoucent  \n",
       "268            aberrances      abjuratrices  \n",
       "269         acquiescemens     acquiescement  \n",
       "270          concupiscent           fascent  \n",
       "271           concupisces           drosces  \n",
       "272            absconsent         accensent  \n",
       "273              abaisses          abbesses  \n",
       "274          abaissassent        abalassent  \n",
       "275           abaissasses         abalasses  \n",
       "276          smithsonites                    \n",
       "277               trénitz             Anetz  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les statistiques d'un phonème en particulier (ex: \\s\\)\n",
    "phoneme = 's'\n",
    "#hex(ord('s'))\n",
    "dfp[dfp.phonème == phoneme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvEujTABtn3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>s</td>\n",
       "      <td>c’</td>\n",
       "      <td>179</td>\n",
       "      <td>0.00</td>\n",
       "      <td>c’</td>\n",
       "      <td>c’est</td>\n",
       "      <td>c’que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>s</td>\n",
       "      <td>s’</td>\n",
       "      <td>2974</td>\n",
       "      <td>0.00</td>\n",
       "      <td>s’abader</td>\n",
       "      <td>s’abaisser</td>\n",
       "      <td>s’abaisser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>s</td>\n",
       "      <td>ç’</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ç’</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>83651</td>\n",
       "      <td>0.12</td>\n",
       "      <td>abaciste</td>\n",
       "      <td>abacistes</td>\n",
       "      <td>abandogiciel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>s</td>\n",
       "      <td>ç</td>\n",
       "      <td>10867</td>\n",
       "      <td>0.01</td>\n",
       "      <td>accoinçon</td>\n",
       "      <td>accoinçons</td>\n",
       "      <td>agaça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>291936</td>\n",
       "      <td>0.44</td>\n",
       "      <td>aaronisme</td>\n",
       "      <td>aaronismes</td>\n",
       "      <td>aasax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>s</td>\n",
       "      <td>sc</td>\n",
       "      <td>5355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abscise</td>\n",
       "      <td>abscises</td>\n",
       "      <td>abscision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>s</td>\n",
       "      <td>th</td>\n",
       "      <td>135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>chrestomathie</td>\n",
       "      <td>chrestomathies</td>\n",
       "      <td>classpath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>s</td>\n",
       "      <td>x</td>\n",
       "      <td>504</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antisoixantehuitard</td>\n",
       "      <td>antisoixantehuitards</td>\n",
       "      <td>auxerrois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>s</td>\n",
       "      <td>cc</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>accensa</td>\n",
       "      <td>accensai</td>\n",
       "      <td>accensaient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>s</td>\n",
       "      <td>ce</td>\n",
       "      <td>6310</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayance</td>\n",
       "      <td>aberrance</td>\n",
       "      <td>abjuratrice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>s</td>\n",
       "      <td>sç</td>\n",
       "      <td>112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesça</td>\n",
       "      <td>acquiesçable</td>\n",
       "      <td>acquiesçables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>s</td>\n",
       "      <td>se</td>\n",
       "      <td>1879</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaissemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>s</td>\n",
       "      <td>ss</td>\n",
       "      <td>120904</td>\n",
       "      <td>0.18</td>\n",
       "      <td>abadassiez</td>\n",
       "      <td>abadassions</td>\n",
       "      <td>abaissassiez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>s</td>\n",
       "      <td>sse</td>\n",
       "      <td>33159</td>\n",
       "      <td>0.05</td>\n",
       "      <td>abadasse</td>\n",
       "      <td>abaissasse</td>\n",
       "      <td>abalasse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>s</td>\n",
       "      <td>sth</td>\n",
       "      <td>97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatiques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>28322</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abaliénation</td>\n",
       "      <td>abaliénations</td>\n",
       "      <td>abannation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>s</td>\n",
       "      <td>z</td>\n",
       "      <td>453</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>s</td>\n",
       "      <td>cent</td>\n",
       "      <td>421</td>\n",
       "      <td>0.00</td>\n",
       "      <td>agacent</td>\n",
       "      <td>agencent</td>\n",
       "      <td>agoucent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>s</td>\n",
       "      <td>ces</td>\n",
       "      <td>3365</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayances</td>\n",
       "      <td>aberrances</td>\n",
       "      <td>abjuratrices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>s</td>\n",
       "      <td>sce</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesce</td>\n",
       "      <td>acquiescemens</td>\n",
       "      <td>acquiescement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>s</td>\n",
       "      <td>scent</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiescent</td>\n",
       "      <td>concupiscent</td>\n",
       "      <td>fascent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>s</td>\n",
       "      <td>sces</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesces</td>\n",
       "      <td>concupisces</td>\n",
       "      <td>drosces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>s</td>\n",
       "      <td>sent</td>\n",
       "      <td>355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaissent</td>\n",
       "      <td>absconsent</td>\n",
       "      <td>accensent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>s</td>\n",
       "      <td>ses</td>\n",
       "      <td>1110</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abbesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>s</td>\n",
       "      <td>ssent</td>\n",
       "      <td>29948</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadassent</td>\n",
       "      <td>abaissassent</td>\n",
       "      <td>abalassent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>s</td>\n",
       "      <td>sses</td>\n",
       "      <td>30369</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadasses</td>\n",
       "      <td>abaissasses</td>\n",
       "      <td>abalasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>s</td>\n",
       "      <td>ths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>classpaths</td>\n",
       "      <td>smithsonites</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>s</td>\n",
       "      <td>tz</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anetziens</td>\n",
       "      <td>trénitz</td>\n",
       "      <td>Anetz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage            exemple_1  \\\n",
       "249       s       c’         179         0.00                   c’   \n",
       "250       s       s’        2974         0.00             s’abader   \n",
       "251       s       ç’           1         0.00                   ç’   \n",
       "252       s        c       83651         0.12             abaciste   \n",
       "253       s        ç       10867         0.01            accoinçon   \n",
       "254       s        s      291936         0.44            aaronisme   \n",
       "255       s       sc        5355         0.00              abscise   \n",
       "256       s       th         135         0.00        chrestomathie   \n",
       "257       s        x         504         0.00  antisoixantehuitard   \n",
       "258       s       cc          52         0.00              accensa   \n",
       "259       s       ce        6310         0.00             abayance   \n",
       "260       s       sç         112         0.00            acquiesça   \n",
       "261       s       se        1879         0.00              abaisse   \n",
       "262       s       ss      120904         0.18           abadassiez   \n",
       "263       s      sse       33159         0.05             abadasse   \n",
       "264       s      sth          97         0.00      antiasthmatique   \n",
       "265       s        t       28322         0.04         abaliénation   \n",
       "266       s        z         453         0.00            abertzale   \n",
       "267       s     cent         421         0.00              agacent   \n",
       "268       s      ces        3365         0.00            abayances   \n",
       "269       s      sce          16         0.00            acquiesce   \n",
       "270       s    scent           7         0.00          acquiescent   \n",
       "271       s     sces          10         0.00           acquiesces   \n",
       "272       s     sent         355         0.00            abaissent   \n",
       "273       s      ses        1110         0.00             abaisses   \n",
       "274       s    ssent       29948         0.04           abadassent   \n",
       "275       s     sses       30369         0.04            abadasses   \n",
       "276       s      ths           2         0.00           classpaths   \n",
       "277       s       tz          12         0.00            anetziens   \n",
       "\n",
       "                exemple_2         exemple_3  \n",
       "249                 c’est             c’que  \n",
       "250            s’abaisser        s’abaisser  \n",
       "251                                          \n",
       "252             abacistes      abandogiciel  \n",
       "253            accoinçons             agaça  \n",
       "254            aaronismes             aasax  \n",
       "255              abscises         abscision  \n",
       "256        chrestomathies         classpath  \n",
       "257  antisoixantehuitards         auxerrois  \n",
       "258              accensai       accensaient  \n",
       "259             aberrance       abjuratrice  \n",
       "260          acquiesçable     acquiesçables  \n",
       "261               abaisse       abaissemens  \n",
       "262           abadassions      abaissassiez  \n",
       "263            abaissasse          abalasse  \n",
       "264       antiasthmatique  antiasthmatiques  \n",
       "265         abaliénations        abannation  \n",
       "266             abertzale        abertzales  \n",
       "267              agencent          agoucent  \n",
       "268            aberrances      abjuratrices  \n",
       "269         acquiescemens     acquiescement  \n",
       "270          concupiscent           fascent  \n",
       "271           concupisces           drosces  \n",
       "272            absconsent         accensent  \n",
       "273              abaisses          abbesses  \n",
       "274          abaissassent        abalassent  \n",
       "275           abaissasses         abalasses  \n",
       "276          smithsonites                    \n",
       "277               trénitz             Anetz  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp[dfp.phonème == phoneme]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTLaTRWYJn2r"
   },
   "source": [
    "## Bilan des correspondances non trouvées\n",
    "\n",
    "* Normalement, aucune ligne ne devrait être affichée (si noms communs, noms propres et sigles analysés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Df8fmZunHd7r"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>ɥ</td>\n",
       "      <td>’hu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>ɛ</td>\n",
       "      <td>eighs</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>œ̃</td>\n",
       "      <td>Hun</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>œ̃</td>\n",
       "      <td>Huns</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>œ</td>\n",
       "      <td>ogl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ø</td>\n",
       "      <td>hœ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>ø</td>\n",
       "      <td>euent</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>o</td>\n",
       "      <td>hoa</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>ɑ̃</td>\n",
       "      <td>aën</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>a</td>\n",
       "      <td>acts</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>aj</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>aj</td>\n",
       "      <td>igh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ɡz</td>\n",
       "      <td>xh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>ɔɛ</td>\n",
       "      <td>œ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>tʃ</td>\n",
       "      <td>ch</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>tʃ</td>\n",
       "      <td>œ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage exemple_1 exemple_2 exemple_3\n",
       "380       ɥ      ’hu           0          0.0                              \n",
       "532       ɛ    eighs           0          0.0                              \n",
       "584      œ̃      Hun           0          0.0                              \n",
       "585      œ̃     Huns           0          0.0                              \n",
       "605       œ      ogl           0          0.0                              \n",
       "619       ø       hœ           0          0.0                              \n",
       "627       ø    euent           0          0.0                              \n",
       "747       o      hoa           0          0.0                              \n",
       "846      ɑ̃      aën           0          0.0                              \n",
       "916       a     acts           0          0.0                              \n",
       "944      aj        j           0          0.0                              \n",
       "945      aj      igh           0          0.0                              \n",
       "958      ɡz       xh           0          0.0                              \n",
       "959      ɔɛ        œ           0          0.0                              \n",
       "960      tʃ       ch           0          0.0                              \n",
       "962      tʃ        œ           0          0.0                              "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "dfp[dfp.occurences == 0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test_de_plausibité.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
