{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcBwaujqj7wg"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Ce programme a pour but de tester la plausibilité de la prononciation d'un mot telle qu'indiquée sur le Wiktionnaire.\n",
    "\n",
    "Pour ce faire, il parcours itérativement les différents sons (phonemes) d'un mot et essaie les différentes lettres (graphemes) pouvant être utilisées pour écrire le son (grâce à une table de correspondance similaire à https://fr.wiktionary.org/wiki/Annexe:Prononciation/français#Troisième_approche). A chaque essai, il compare ce qu'il obtient avec l'orthographe utilisée dans le Wiktionnaire. Lorsqu'il arrive au même résultat, la prononciation du mot est jugée plausible. A l'inverse, s'il n'arrive pas à transcrire la même orthographe que celle indiquée dans le Wiktionnaire, la prononciation est jugée suspecte.\n",
    "\n",
    "Ce programme peut aussi compter les différentes lettres utilisées pour transcrire un son. Ainsi, s'il est executé sur tous les mots du Wiktionnaire, il peut servir à compter les probabilités de ces lettres pour transcrire un son donné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iczXUEW6x1g"
   },
   "source": [
    "## Données d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zD26Opi6hhPK"
   },
   "outputs": [],
   "source": [
    "# importation des librairies tierces\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# lecture des données d'entrée (ligne contenant un mot du dictionnaire\n",
    "# ainsi que sa prononciation\n",
    "def read_df():\n",
    "\n",
    "  '''Read the input data (i.e. lines containing a Wiktionary word \n",
    "  and its pronunciation) '''\n",
    "  filename = '../wikt_parser/fr_wiktionary_full.csv'\n",
    "  #filename = '../wikt_parser/fr_wiktionary_waves.csv'\n",
    "    \n",
    "  filepath = Path(filename)\n",
    "\n",
    "  url = 'https://fonétik.fr/'\n",
    "  url_filename = url + filename\n",
    "\n",
    "  #print('downloading ', url_filename)\n",
    "  # if file not found locally, then download it\n",
    "  #if not filepath.exists():\n",
    "  #  !wget -N -q {url_filename}\n",
    "\n",
    "  df = pd.read_csv(filename, keep_default_na=False, sep = '\\t')\n",
    "\n",
    "  return df\n",
    "\n",
    "df = read_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "e8LX-nHWXKQg",
    "outputId": "3d969ca8-f285-451a-cf15-4ff81bdd3c6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1518039</th>\n",
       "      <td>’tit</td>\n",
       "      <td>ti</td>\n",
       "      <td>False</td>\n",
       "      <td>adjectif</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518040</th>\n",
       "      <td>’upa’upa</td>\n",
       "      <td>u.pa.u.pa</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518041</th>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518042</th>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518043</th>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot  Prononciation  H_aspiré           Type Audios  Pré_valide  \\\n",
       "1518039      ’tit             ti     False       adjectif     []        True   \n",
       "1518040  ’upa’upa      u.pa.u.pa     False            nom     []        True   \n",
       "1518041         €           ø.ʁo     False        symbole     []       False   \n",
       "1518042         ℁  o bɔ̃ swɛ̃ də     False    préposition     []       False   \n",
       "1518043         ∴      mɔʁ‿o.vaʃ     False  symbole_num=2     []       False   \n",
       "\n",
       "              Warn_code         Warn_label  \n",
       "1518039               -                  -  \n",
       "1518040               -                  -  \n",
       "1518041  err_lower_case  €_as_first_letter  \n",
       "1518042  err_lower_case  ℁_as_first_letter  \n",
       "1518043  err_lower_case  ∴_as_first_letter  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PmidCDRIAwl"
   },
   "outputs": [],
   "source": [
    "# corriger les & mal-formatés s'il y a en\n",
    "df['Mot'] = df['Mot'].str.replace('&amp;', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XIBkXvacY5sH",
    "outputId": "4c4b2df2-7a5a-4fc7-d528-7a2fc982de78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518044"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage du nombre d'échantillons en entrées\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COxsRMd09a1s"
   },
   "outputs": [],
   "source": [
    "df['Plausible'] = '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "fGy2OiKXEkQm",
    "outputId": "d5299641-eec8-4f01-df56-a86be98911eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616362</th>\n",
       "      <td>faire avorter une couvée de singes</td>\n",
       "      <td>fɛ.ʁ‿a.vɔʁ.te yn ku.ve də sɛ̃ʒ</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe</td>\n",
       "      <td>['LL-Q150 (fra)-WikiLucas00-faire avorter une ...</td>\n",
       "      <td>False</td>\n",
       "      <td>err_too_many_spaces</td>\n",
       "      <td>5_spaces</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766438</th>\n",
       "      <td>lardiers</td>\n",
       "      <td>laʁ.dje</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469361</th>\n",
       "      <td>zemb</td>\n",
       "      <td>zamb</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211723</th>\n",
       "      <td>blâtrai</td>\n",
       "      <td>bla.tʁe</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254798</th>\n",
       "      <td>cannibalisions</td>\n",
       "      <td>ka.ni.ba.li.zjɔ̃</td>\n",
       "      <td>False</td>\n",
       "      <td>verbe_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Mot                   Prononciation  \\\n",
       "616362   faire avorter une couvée de singes  fɛ.ʁ‿a.vɔʁ.te yn ku.ve də sɛ̃ʒ   \n",
       "766438                             lardiers                         laʁ.dje   \n",
       "1469361                                zemb                            zamb   \n",
       "211723                              blâtrai                         bla.tʁe   \n",
       "254798                       cannibalisions                ka.ni.ba.li.zjɔ̃   \n",
       "\n",
       "         H_aspiré           Type  \\\n",
       "616362      False          verbe   \n",
       "766438      False    nom_flexion   \n",
       "1469361     False            nom   \n",
       "211723      False  verbe_flexion   \n",
       "254798      False  verbe_flexion   \n",
       "\n",
       "                                                    Audios  Pré_valide  \\\n",
       "616362   ['LL-Q150 (fra)-WikiLucas00-faire avorter une ...       False   \n",
       "766438                                                  []        True   \n",
       "1469361                                                 []        True   \n",
       "211723                                                  []        True   \n",
       "254798                                                  []        True   \n",
       "\n",
       "                   Warn_code Warn_label Plausible  \n",
       "616362   err_too_many_spaces   5_spaces         ?  \n",
       "766438                     -          -         ?  \n",
       "1469361                    -          -         ?  \n",
       "211723                     -          -         ?  \n",
       "254798                     -          -         ?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage de 5 derniers échantillons\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "su8M2cf-AGNl",
    "outputId": "9b4be442-25bf-4745-e68e-4b23b8bca0c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1281283</th>\n",
       "      <td>résumpte</td>\n",
       "      <td>ʁe.zɔ̃pt</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281284</th>\n",
       "      <td>résumpte</td>\n",
       "      <td>ʁe.zɔ̃t</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot Prononciation  H_aspiré Type Audios  Pré_valide Warn_code  \\\n",
       "1281283  résumpte      ʁe.zɔ̃pt     False  nom     []        True         -   \n",
       "1281284  résumpte       ʁe.zɔ̃t     False  nom     []        True         -   \n",
       "\n",
       "        Warn_label Plausible  \n",
       "1281283          -         ?  \n",
       "1281284          -         ?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Mot=='résumpte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpcCm53fcXVl"
   },
   "source": [
    "## Table de correspondance entre sons et lettres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def read_table_de_correspondance():\n",
    "    df = pd.read_csv(\"table_de_correspondances.csv\")\n",
    "    phonemes2graphemes = {}\n",
    "    for phoneme in df.Phonème.values:\n",
    "        for position in df[df.Phonème == phoneme].Position.values:\n",
    "            for grapheme in df[df.Phonème == phoneme][df.Position == position].Graphème.values:\n",
    "                if phoneme not in phonemes2graphemes.keys():\n",
    "                    phonemes2graphemes[phoneme] = {}\n",
    "                phonemes2graphemes[phoneme][grapheme] = {}\n",
    "            \n",
    "    return phonemes2graphemes\n",
    "\n",
    "phonemes2graphemes = read_table_de_correspondance()\n",
    "\n",
    "def add_keys(phonemes2graphemes):\n",
    "  '''Ajoute des clés ('occurences', 'exemple_1', 'exemple_2', 'exemple_3')\n",
    "   dans le dictionnaire de chaque grapheme de la table phonemes2graphemes.'''\n",
    "\n",
    "  for phoneme in phonemes2graphemes.keys():\n",
    "    #for position in phonemes2graphemes[phoneme].keys():\n",
    "      for grapheme in phonemes2graphemes[phoneme].keys():\n",
    "        phonemes2graphemes[phoneme][grapheme]['occurences'] = 0\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_1'] = ''\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_2'] = ''\n",
    "        phonemes2graphemes[phoneme][grapheme]['exemple_3'] = ''\n",
    "\n",
    "  return phonemes2graphemes\n",
    "\n",
    "# run add_keys\n",
    "phonemes2graphemes = add_keys(phonemes2graphemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsDUfNANiXDs"
   },
   "source": [
    "## Fonctions de comptage pour statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-r1cTpGHmAso"
   },
   "outputs": [],
   "source": [
    "# fonction de comptage qui incrémente d'une unité le compteur de correspondance\n",
    "# entre un phonème donné et un graphème donné et qui enregistre en exemple \n",
    "# les trois premiers mots dans lequels la correspondance a été trouvé \n",
    "def increment_occurences(phoneme, grapheme, mot, unit_test=False):\n",
    "  \n",
    "  global phonemes2graphemes\n",
    "\n",
    "  # ne pas continuer si l'appel provient d'un test unitaire\n",
    "  if unit_test:\n",
    "    return\n",
    "\n",
    "  phonemes2graphemes[phoneme][grapheme]['occurences']  += 1\n",
    "  if phonemes2graphemes[phoneme][grapheme]['exemple_1']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_1'] = mot\n",
    "  elif phonemes2graphemes[phoneme][grapheme]['exemple_2']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_2'] = mot\n",
    "  elif phonemes2graphemes[phoneme][grapheme]['exemple_3']  == '':\n",
    "    phonemes2graphemes[phoneme][grapheme]['exemple_3'] = mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "nNXz97yImhDC",
    "outputId": "8ad76acb-a3d3-4526-b185-a14aa62197e4"
   },
   "outputs": [],
   "source": [
    "# fonction de statistiques qui calcule pour pour chaque position (initiale,\n",
    "# intermédiaire ou finale) le nombre d'occurences de chaque graphème ainsi\n",
    "# que la probabilité de ce graphème.\n",
    "# Les résultats sont insérés dans un DataFrame pandas et dans un fichier CSV.\n",
    "\n",
    "def make_stats():\n",
    "  global phonemes2graphemes\n",
    "\n",
    "  table = []\n",
    "  for phoneme in phonemes2graphemes:\n",
    "      for grapheme in phonemes2graphemes[phoneme].keys():\n",
    "        occurences = phonemes2graphemes[phoneme][grapheme]['occurences']\n",
    "        exemple_1 = phonemes2graphemes[phoneme][grapheme]['exemple_1']\n",
    "        exemple_2 = phonemes2graphemes[phoneme][grapheme]['exemple_2']\n",
    "        exemple_3 = phonemes2graphemes[phoneme][grapheme]['exemple_3']\n",
    "\n",
    "        #print(\"phoneme=%s grapheme=%s occurences=%d\" % (phoneme, grapheme, occurences))\n",
    "        row = { 'phonème': phoneme, 'graphème':grapheme, 'occurences':occurences, 'pourcentage':0.0,\n",
    "               'exemple_1' : exemple_1, 'exemple_2' : exemple_2, 'exemple_3' : exemple_3, }\n",
    "        table.append(row)\n",
    "  dfp = pd.DataFrame.from_dict(table)\n",
    "\n",
    "  for phoneme in dfp['phonème'].unique():\n",
    "      df1 = dfp[dfp['phonème'] == phoneme]\n",
    "\n",
    "      # calculate the sum of used graphemes within each phoneme-position category\n",
    "      sum = 0\n",
    "      for grapheme in df1['graphème'].unique():\n",
    "        row_number = df1.loc[df1.graphème==grapheme].index[0]\n",
    "        occurences = df1.at[row_number, 'occurences']\n",
    "        sum += occurences\n",
    "\n",
    "      # set the pourcentage of each graphemes for each phoneme-position category\n",
    "      if sum != 0:\n",
    "        for grapheme in df1['graphème'].unique():\n",
    "          row_number = df1.loc[df1.graphème==grapheme].index[0]\n",
    "          occurences = df1.at[row_number, 'occurences']\n",
    "          pourcentage = int(occurences/sum*100)/100\n",
    "          dfp.at[row_number, 'pourcentage'] = pourcentage\n",
    "\n",
    "      dfp.to_csv(\"phonemes2graphemes.csv\", index=False)\n",
    "\n",
    "  return dfp\n",
    "\n",
    "_ = make_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1v0fIw3nuU8"
   },
   "source": [
    "## Fonction de test de plausibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeQZ2cWYoCQG"
   },
   "outputs": [],
   "source": [
    "# Fonction récursive tentant de retrouver tout ou partie des graphemes\n",
    "# depuis tout ou partie des phonemes, à l'aide de la table de correspondance\n",
    "# entre les phonemes et les graphemes.\n",
    "\n",
    "def process_graphemes(mot, phonemes, graphemes, \n",
    "                      phoneme_index=0, grapheme_index=0, \n",
    "                      phonemes_hist='', graphemes_hist='', \n",
    "                      unit_test = False, verbose=False,):\n",
    "  \n",
    "  if verbose:\n",
    "    print('')\n",
    "    print('process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], \\\n",
    "    phoneme_index=%d, grapheme_index=%d, \\\n",
    "    phonemes_hist=%s, graphemes_hist=%s)' \n",
    "            % (phonemes, graphemes, phoneme_index, grapheme_index, phonemes_hist, graphemes_hist))\n",
    "\n",
    "  global phonemes2graphemes\n",
    "\n",
    "  if grapheme_index >= len(graphemes):\n",
    "    if ''.join(graphemes_hist) == graphemes and ''.join(phonemes_hist)==phonemes:\n",
    "        if verbose:\n",
    "            print('ended ok')            \n",
    "        return True, phonemes_hist.copy(), graphemes_hist.copy()\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('ended ko')\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "  current_candidate_phonemes = []\n",
    "  for phoneme in phonemes2graphemes:    \n",
    "    if phonemes[phoneme_index:].startswith(phoneme):      \n",
    "      current_candidate_phonemes.append(phoneme)\n",
    "  if len(current_candidate_phonemes) == 0:\n",
    "    return False, phonemes_hist, graphemes_hist\n",
    "  if verbose:\n",
    "    if len(current_candidate_phonemes) > 1:\n",
    "      print(\"### candidate current phonemes=%\", current_candidate_phonemes)\n",
    "\n",
    "  nb_current_candidate_phonemes = 0 \n",
    "\n",
    "  for current_phoneme in current_candidate_phonemes:\n",
    "    if verbose:\n",
    "      print(\"trying candidate current phoneme=%s\" % current_phoneme)\n",
    "    nb_current_candidate_phonemes += 1\n",
    "    next_phoneme = ''\n",
    "\n",
    "    last_graphemes = graphemes[grapheme_index:]\n",
    "    \n",
    "    if verbose:\n",
    "      print('process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], phoneme_index=%d, grapheme_index=%d) current_phoneme:%s' \n",
    "            % (phonemes, graphemes, phoneme_index, grapheme_index, current_phoneme))\n",
    "  \n",
    "    if verbose:\n",
    "      print('current_phoneme:%s' % current_phoneme)\n",
    "    \n",
    "    try:\n",
    "      len(phonemes2graphemes[current_phoneme])\n",
    "    except:\n",
    "      a=1\n",
    "      if current_phoneme == '':\n",
    "        if verbose:\n",
    "          print('wrn: in [[%s]] : phoneme \\\\%s\\\\ does not exist !!!' % (graphemes, current_phoneme))\n",
    "        return True, phonemes_hist, graphemes_hist\n",
    "      else:\n",
    "        print('err: in [[%s]] : phoneme \\\\%s\\\\ does not exist !!!' % (graphemes, current_phoneme))\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "    matching_graphemes_list = []\n",
    "\n",
    "    for current_graphemes in phonemes2graphemes[current_phoneme]:\n",
    "    \n",
    "      if last_graphemes.startswith(current_graphemes):\n",
    "        if verbose:\n",
    "          print('phoneme \\\\%s\\\\ matching graphemes [[%s]] (last_graphemes:[[%s]])' % (current_phoneme, current_graphemes, last_graphemes))\n",
    "        matching_graphemes_list.append(current_graphemes)\n",
    "\n",
    "    if len(matching_graphemes_list) == 0:\n",
    "      if verbose:\n",
    "        print('KO0: phonemes=\\\\%s\\\\ does not match any grapheme !!!' % (phonemes))\n",
    "\n",
    "      if nb_current_candidate_phonemes == len(current_candidate_phonemes):\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "      else:\n",
    "        if verbose:\n",
    "          print('move0 to next candidate phoneme')\n",
    "        continue\n",
    "      \n",
    "    #print('current_phoneme=', current_phoneme)\n",
    "    \n",
    "    ### * ###\n",
    "    if len(matching_graphemes_list) == 0:\n",
    "        if verbose:\n",
    "          print('KO: phoneme \\\\%s\\\\ matches NO grapheme (in word [[%s]])  !!!' % (graphemes, phonemes))\n",
    "        phonemes_hist.pop()\n",
    "        graphemes_hist.pop()\n",
    "        return False, phonemes_hist, graphemes_hist\n",
    "\n",
    "    for current_graphemes in matching_graphemes_list:\n",
    "        \n",
    "        phonemes_hist.append(current_phoneme)\n",
    "        graphemes_hist.append(current_graphemes)\n",
    "\n",
    "        if verbose:\n",
    "          print(\"trying2 current_phoneme \\\\%s\\\\ and current_graphemes [[%s]]\" % (current_phoneme, current_graphemes))\n",
    "\n",
    "        ret, phonemes_hist2, graphemes_hist2 = process_graphemes(\n",
    "            mot,\n",
    "            phonemes, \n",
    "            graphemes,\n",
    "            phoneme_index=phoneme_index+len(current_phoneme), \n",
    "            grapheme_index=grapheme_index+len(current_graphemes),\n",
    "            phonemes_hist = phonemes_hist,\n",
    "            graphemes_hist = graphemes_hist,\n",
    "            unit_test = unit_test,\n",
    "            verbose=verbose)           \n",
    "                \n",
    "        # si la concatenation des graphemes trouvées jusqu'ici n'est pas bonne, alors pas bon\n",
    "        if not graphemes.startswith(''.join(graphemes_hist)):\n",
    "            if verbose:\n",
    "                print(''.join(graphemes_hist)+current_graphemes)\n",
    "                print(graphemes)\n",
    "                print('current_graphemes does not match previous findings')\n",
    "            ret = False          \n",
    "                \n",
    "          # si la concatenation des graphemes trouvées jusqu'ici n'est pas bonne, alors pas bon\n",
    "\n",
    "      \n",
    "        if ret == True:\n",
    "          if verbose:\n",
    "            print('phonemes_hist2b:', phonemes_hist2)\n",
    "            print('graphemes_hist2b:', graphemes_hist2)\n",
    "            print(\"current_phoneme \\\\%s\\\\ and current_graphemes [[%s]] : worked ok\" % (current_phoneme, current_graphemes))\n",
    "          \n",
    "          increment_occurences(current_phoneme, current_graphemes, mot, unit_test)\n",
    "          return True, phonemes_hist2, graphemes_hist2\n",
    "    \n",
    "        phonemes_hist.pop()\n",
    "        graphemes_hist.pop()\n",
    "      \n",
    "    # if here LOST\n",
    "    if verbose:\n",
    "          print('LOST2 for current_phoneme \\\\%s\\\\ in process_graphemes(phonemes=\\\\%s\\\\, graphemes=[[%s]], phoneme_index=%d, grapheme_index=%d)' \n",
    "                % (current_phoneme, phonemes, graphemes, phoneme_index, grapheme_index))\n",
    "    \n",
    "    if nb_current_candidate_phonemes == len(current_candidate_phonemes):\n",
    "        return False, phonemes_hist2, graphemes_hist2\n",
    "    else:\n",
    "       \n",
    "        if verbose:\n",
    "          print('move2 to next candidate phoneme')\n",
    "        continue\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZlfYwF1opiA"
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOS9qKRWzO42"
   },
   "source": [
    "### Exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhYXjOSbo9_I"
   },
   "outputs": [],
   "source": [
    "exemples = [\n",
    "    (\"momie\", \"mɔmi\"),\n",
    "    (\"pookie\", \"puki\"),\n",
    "\n",
    "]\n",
    "\n",
    "for exemple in exemples:\n",
    "    \n",
    "    mot = exemple[0]\n",
    "    graphemes = exemple[0]\n",
    "    phonemes = exemple[1]\n",
    "    \n",
    "    res = process_graphemes(mot, phonemes, graphemes, \n",
    "                            phoneme_index=0, grapheme_index=0, \n",
    "                            phonemes_hist=[], graphemes_hist=[],\n",
    "                            unit_test=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uh0wZe67re4Z"
   },
   "outputs": [],
   "source": [
    "def check_word_pronunciation(mot, phonemes, graphemes, unit_test=False, verbose0=False, verbose1=False, verbose2=False):\n",
    "\n",
    "    res, phonemes2, graphemes2  = process_graphemes(mot, phonemes, graphemes, phoneme_index=0, grapheme_index=0, phonemes_hist=[], graphemes_hist=[], unit_test=unit_test, verbose=verbose2)\n",
    "    prononciation = ''.join(phonemes2)\n",
    "    word = ''.join(graphemes2)\n",
    "    prononciation_ = ','.join(phonemes2)\n",
    "    word_ = ','.join(graphemes2)\n",
    "    if prononciation != phonemes:\n",
    "      if verbose0:\n",
    "        print('[[%s]] \\\\%s\\\\ -> prononciation=\\\\%s\\\\ ' % (mot, phonemes, prononciation ))\n",
    "      return False\n",
    "    elif word != graphemes.replace('-','').replace(' ',''):\n",
    "      if verbose0:\n",
    "        print('[[%s]] != output graphemes=%s' % (mot, word))\n",
    "      return True\n",
    "    else:\n",
    "      if verbose0:\n",
    "        print('%s \\\\%s\\\\ -> %s \\\\%s\\\\' % (mot, prononciation, word_, prononciation_))\n",
    "      return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXWXcxH2xf-A"
   },
   "source": [
    "### Tests de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "4CZD_l1chhQO",
    "outputId": "6b3a727a-dd48-46fc-ff70-7b99fe30cb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acéphalobrache \\asefalɔbʁak\\ -> a,c,é,ph,a,l,o,b,r,a,che \\a,s,e,f,a,l,ɔ,b,ʁ,a,k\\\n",
      "acquaintance \\akwɛ̃tɑ̃s\\ -> a,cq,u,ain,t,an,ce \\a,k,w,ɛ̃,t,ɑ̃,s\\\n",
      "agoua \\aɡwa\\ -> a,g,ou,a \\a,ɡ,w,a\\\n",
      "bêchâmes \\beʃam\\ -> b,ê,ch,â,mes \\b,e,ʃ,a,m\\\n",
      "caouanne \\kawan\\ -> c,a,ou,a,nne \\k,a,w,a,n\\\n",
      "designer \\dizajnœʁ\\ -> d,e,s,i,g,n,e,r \\d,i,z,a,j,n,œ,ʁ\\\n",
      "désembouteillions \\dezɑ̃butɛjɔ̃\\ -> d,é,s,em,b,ou,t,e,illi,ons \\d,e,z,ɑ̃,b,u,t,ɛ,j,ɔ̃\\\n",
      "disjonctés \\diʒɔ̃kte\\ -> d,is,j,on,c,t,és \\d,i,ʒ,ɔ̃,k,t,e\\\n",
      "droitismes \\dʁwatism\\ -> d,r,o,i,t,i,s,mes \\d,ʁ,w,a,t,i,s,m\\\n",
      "élégante \\eleɡɑ̃t\\ -> é,l,é,g,an,te \\e,l,e,ɡ,ɑ̃,t\\\n",
      "enarrhas \\ɑ̃naʁa\\ -> e,n,a,rrh,as \\ɑ̃,n,a,ʁ,a\\\n",
      "enfutailler \\ɑ̃fytɑje\\ -> en,f,u,t,a,ill,er \\ɑ̃,f,y,t,ɑ,j,e\\\n",
      "excaverai \\ɛkskavəʁe\\ -> e,x,c,a,v,e,r,ai \\ɛ,ks,k,a,v,ə,ʁ,e\\\n",
      "exemple \\ɛɡzɑ̃pl\\ -> e,x,em,p,le \\ɛ,ɡz,ɑ̃,p,l\\\n",
      "fashion \\faʃœn\\ -> f,a,sh,io,n \\f,a,ʃ,œ,n\\\n",
      "khartoumisé \\kaʁtumize\\ -> k,ha,r,t,ou,m,i,s,é \\k,a,ʁ,t,u,m,i,z,e\\\n",
      "hauts \\o\\ -> hauts \\o\\\n",
      "hauts-fonds \\ofɔ̃\\ -> hauts,f,onds \\o,f,ɔ̃\\\n",
      "html \\aʃteɛmɛl\\ -> h,t,m,l \\aʃ,te,ɛm,ɛl\\\n",
      "intérêt \\ɛ̃teʁɛ\\ -> in,t,é,r,êt \\ɛ̃,t,e,ʁ,ɛ\\\n",
      "intéressant \\ɛ̃teʁɛsɑ̃\\ -> in,t,é,r,es,s,ant \\ɛ̃,t,e,ʁ,ɛ,s,ɑ̃\\\n",
      "jaïnas \\dʒaina\\ -> j,a,ï,n,as \\dʒ,a,i,n,a\\\n",
      "luxe \\lyks\\ -> l,u,xe \\l,y,ks\\\n",
      "momie \\mɔmi\\ -> m,o,m,ie \\m,ɔ,m,i\\\n",
      "oiseaux \\wazo\\ -> o,i,s,eaux \\w,a,z,o\\\n",
      "ondoyés \\ɔ̃dwaje\\ -> on,d,o,y,és \\ɔ̃,d,w,aj,e\\\n",
      "peopliser \\piplize\\ -> p,eo,p,l,i,s,er \\p,i,p,l,i,z,e\\\n",
      "pookie \\puki\\ -> p,oo,k,ie \\p,u,k,i\\\n",
      "rechaterais \\ʁətʃatəʁɛ\\ -> r,e,c,h,a,t,e,r,ais \\ʁ,ə,t,ʃ,a,t,ə,ʁ,ɛ\\\n",
      "solex \\solɛks\\ -> s,o,l,e,x \\s,o,l,ɛ,ks\\\n",
      "Paris \\paʁi\\ -> p,a,r,is \\p,a,ʁ,i\\\n",
      "VPN \\vepeɛn\\ -> v,p,n \\ve,pe,ɛn\\\n"
     ]
    }
   ],
   "source": [
    "essais = [\n",
    "    (\"acéphalobrache\", \"asefalɔbʁak\"),\n",
    "    (\"acquaintance\",\"akwɛ̃tɑ̃s\"),\n",
    "    (\"agoua\",\"aɡwa\"),\n",
    "    (\"bêchâmes\",\"beʃam\"),\n",
    "    (\"caouanne\",\"kawan\"),\n",
    "    (\"designer\",\"dizajnœʁ\"),\n",
    "    (\"désembouteillions\",\"dezɑ̃butɛjɔ̃\"),\n",
    "    (\"disjonctés\",\"diʒɔ̃kte\"),\n",
    "    (\"droitismes\", \"dʁwatism\"),\n",
    "    (\"élégante\", \"eleɡɑ̃t\"),\n",
    "    (\"enarrhas\", \"ɑ̃naʁa\"),\n",
    "    (\"enfutailler\", \"ɑ̃fytɑje\"),\n",
    "    (\"excaverai\", \"ɛkskavəʁe\"),\n",
    "    (\"exemple\", \"ɛɡzɑ̃pl\"),\n",
    "    (\"fashion\",\"faʃœn\"),\n",
    "    (\"khartoumisé\",\"kaʁtumize\"),\n",
    "    (\"hauts\", \"o\"),\n",
    "    ('hauts-fonds','o.fɔ̃'),\n",
    "    (\"html\", \"aʃteɛmɛl\"), #acronyme\n",
    "    (\"intérêt\", \"ɛ̃teʁɛ\"),\n",
    "    (\"intéressant\",\"ɛ̃teʁɛsɑ̃\"),\n",
    "    (\"jaïnas\",\"dʒaina\"),\n",
    "    (\"luxe\",\"lyks\"),\n",
    "    (\"momie\",\"mɔmi\"),\n",
    "    (\"oiseaux\", \"wazo\"),\n",
    "    (\"ondoyés\", \"ɔ̃dwaje\"),\n",
    "    (\"peopliser\",\"piplize\"),\n",
    "    (\"pookie\", \"puki\"),\n",
    "    (\"rechaterais\", \"ʁətʃatəʁɛ\"),\n",
    "    ('solex', 'solɛks'),\n",
    "    ('Paris', 'pa.ʁi'),\n",
    "    ('VPN', 've.pe.ɛn'),\n",
    "    \n",
    "]\n",
    "\n",
    "for essai in essais:\n",
    "  #check_word_pronunciation(essai[0], essai[1].replace('.',''), essai[0].lower().replace('-',''), unit_test=True, verbose0=True, verbose1=False, verbose2=False)\n",
    "  check_word_pronunciation(essai[0], essai[1].replace('.',''), essai[0].lower().replace('-',''), unit_test=True, verbose0=True, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_E7sUaT5bd2U"
   },
   "source": [
    "### Test en masse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1aSsYCmh3J0R",
    "outputId": "61692a02-e47c-498f-e447-dcc83f2d84fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1518044, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "pWuUXTC23K8P",
    "outputId": "6aba893e-bae7-41a9-a89d-8637e495fc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb mots composés:161776\n",
      "nb mots préfixes:425\n",
      "nb mots noms communs:1323344\n",
      "nb mots noms propres:29385\n",
      "nb mots sigles:2005\n",
      "nb mots autres:1109\n",
      "nb mots TOTAL:1520049\n"
     ]
    }
   ],
   "source": [
    "# trier le dataframe (noms communs, acronymes, noms propres, puis restants)\n",
    "# pour des exemples plus significatifs dans les statistiques\n",
    "df_composés = df[df.Mot.str.match('..*?[\\-\\ ].*?.')].copy()\n",
    "print(\"nb mots composés:%d\" % df_composés.shape[0])\n",
    "\n",
    "df_autres_0 = pd.concat([df, df_composés, df_composés]).drop_duplicates(keep=False)\n",
    "df_préfixes = df_autres_0[df_autres_0.Mot.str.startswith('-')].copy()\n",
    "print(\"nb mots préfixes:%d\" % df_préfixes.shape[0])\n",
    "\n",
    "df_autres_1 = pd.concat([df_autres_0, df_préfixes, df_préfixes]).drop_duplicates(keep=False)\n",
    "df_nc = df_autres_1[df_autres_1.Mot.str.islower()].copy()\n",
    "print(\"nb mots noms communs:%d\" % df_nc.shape[0])\n",
    "\n",
    "df_autres_2 = pd.concat([df_autres_1, df_nc, df_nc]).drop_duplicates(keep=False)\n",
    "df_np = df_autres_2[df_autres_2.Mot.str.istitle()].copy()\n",
    "print(\"nb mots noms propres:%d\" % df_np.shape[0])\n",
    "\n",
    "df_autres_3 = pd.concat([df_autres_2, df_np, df_np]).drop_duplicates(keep=False)\n",
    "df_sigles = df_autres_3[df_autres_3.Mot.str.isupper()].copy()\n",
    "print(\"nb mots sigles:%d\" % df_sigles.shape[0])\n",
    "\n",
    "df_autres_4 = pd.concat([df_autres_3, df_sigles, df_sigles]).drop_duplicates(keep=False)\n",
    "print(\"nb mots autres:%d\" % df_autres_4.shape[0])\n",
    "\n",
    "# mettre dans un ordre augmentant les probabilités de succès des noms composés\n",
    "df_new = pd.concat([df_nc, df_sigles, df_np, df_composés, df_préfixes, df_sigles, df_autres_4], ignore_index=True).copy()\n",
    "print(\"nb mots TOTAL:%d\" % df_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "aQ_ek99vrt_y",
    "outputId": "0ec71f7e-8912-4d98-9193-bacf6891c823"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1475934</th>\n",
       "      <td>éSwatini</td>\n",
       "      <td>e.swa.ti.ni</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507106</th>\n",
       "      <td>éqCO₂</td>\n",
       "      <td>e.ki.va.lɑ̃ se.o.dø</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_letters</td>\n",
       "      <td>₂</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518041</th>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518042</th>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518043</th>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mot        Prononciation  H_aspiré           Type Audios  \\\n",
       "1475934  éSwatini          e.swa.ti.ni     False     nom propre     []   \n",
       "1507106     éqCO₂  e.ki.va.lɑ̃ se.o.dø     False            nom     []   \n",
       "1518041         €                 ø.ʁo     False        symbole     []   \n",
       "1518042         ℁        o bɔ̃ swɛ̃ də     False    préposition     []   \n",
       "1518043         ∴            mɔʁ‿o.vaʃ     False  symbole_num=2     []   \n",
       "\n",
       "         Pré_valide       Warn_code         Warn_label Plausible  \n",
       "1475934        True               -                  -         ?  \n",
       "1507106       False     err_letters                  ₂         ?  \n",
       "1518041       False  err_lower_case  €_as_first_letter         ?  \n",
       "1518042       False  err_lower_case  ℁_as_first_letter         ?  \n",
       "1518043       False  err_lower_case  ∴_as_first_letter         ?  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_autres_4.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "01jCIjPAhhQp",
    "outputId": "e21472f2-c2e4-443a-e4fc-4e5b78ac271a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1519390, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_new\n",
    "#df2=df2[df2.Mot.str.istitle()] # ne conserver que les mots commençant par une majuscule puis minuscules\n",
    "#df2=df2[df2.Mot.str.islower()] # ne conserver que les mots entièrement en minuscules (i.e. noms communs)\n",
    "#df2=df2[df2.Mot.str.isupper()] # ne conserver que les mots entièrement en majuscules (i.e. acronymes)#\n",
    "#df2=df2[df2.Mot.str.startswith('x')] # ne conserver que les mots noms communs commençant par ...\n",
    "#df2 = pd.concat([df2, df_composés, df_composés]).drop_duplicates(keep=False) # supprimer les mots composés\n",
    "#df2 = df2[~df2.Mot.str.contains(' ')] # exclure les mots contenant un espace\n",
    "#df2 = df2[~df2.Mot.str.contains('-')] # exclure les mots contenant un tiret\n",
    "\n",
    "df2 = df2[~df2.Mot.str.contains('\\.')] # exclure les mots contenant un point\n",
    "df2 = df2[~df2.Mot.str.contains('/')] # exclure les mots contenant un slash (e.g. copier/coller)\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "JOCz6EX3hhQ0",
    "outputId": "2ef3b62b-3112-4ceb-b3c4-49e0e8cb8892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:1, nb_samples:151939, durée:0:00:47.927641\n",
      "batch:2, nb_samples:303878, durée:0:00:46.731340\n",
      "batch:3, nb_samples:455817, durée:0:00:50.981001\n",
      "batch:4, nb_samples:607756, durée:0:00:47.463294\n",
      "batch:5, nb_samples:759695, durée:0:00:47.797715\n",
      "batch:6, nb_samples:911634, durée:0:00:49.343077\n",
      "batch:7, nb_samples:1063573, durée:0:00:50.385440\n",
      "batch:8, nb_samples:1215512, durée:0:00:50.111376\n",
      "batch:9, nb_samples:1367451, durée:0:01:56.199673\n",
      "batch:10, nb_samples:1519390, durée:0:04:34.927574\n",
      "nb_samples: 1519390  durée de processing du dernier batch: 0:00:00.000231\n",
      "samples=1519390, samples_ok=1512382, samples_ko=7008, very_bad=0, ok%=99.54\n"
     ]
    }
   ],
   "source": [
    "nb_samples=0\n",
    "nb_infos_steps=10\n",
    "nb_samples_steps = int(df2.shape[0]/nb_infos_steps)\n",
    "nb_samples_ok=0\n",
    "nb_samples_ko=0\n",
    "nb_very_bad=0\n",
    "nb_batch=0\n",
    "verbose=False\n",
    "indexes_to_forget = []\n",
    "nb_composés = 0\n",
    "nb_composés_directs_found = 0\n",
    "nb_composés_indirects_found = 0\n",
    "\n",
    "t0 = datetime.datetime.now()\n",
    "for index, row in df2.iterrows():\n",
    "\n",
    "    nb_samples += 1\n",
    "    is_ok = False\n",
    "    is_skipped = False\n",
    "        \n",
    "    if nb_samples >= nb_infos_steps and nb_samples % nb_samples_steps == 0:\n",
    "      nb_batch += 1\n",
    "      t1 = datetime.datetime.now()\n",
    "      durée = t1 - t0\n",
    "      print('batch:%d, nb_samples:%d, durée:%s' % (nb_batch, nb_samples, durée))\n",
    "      t0 = t1\n",
    "\n",
    "    mot = row['Mot']\n",
    "    prononciation = row['Prononciation']\n",
    " \n",
    "    is_composé = False\n",
    "    is_composé_direct = False\n",
    "    if ' ' in row['Mot'] or ',' in row['Mot'] or '-' in row['Mot']:\n",
    "      nb_composés += 1     \n",
    "      is_composé = True\n",
    "        \n",
    "    try:\n",
    "      graphemes = row['Mot'].lower().replace(' ', '').replace('-','').replace(',','')\n",
    "      phonemes = prononciation.replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "      is_ok = check_word_pronunciation(mot, phonemes, graphemes, False, False, False, False)\n",
    "          \n",
    "      if is_ok:\n",
    "        if ' ' in row['Mot'] or ',' in row['Mot'] or '-' in row['Mot']:\n",
    "          is_composé_direct = True\n",
    "          nb_composés_directs_found += 1      \n",
    "    \n",
    "    except:\n",
    "      is_ok = False\n",
    "      is_skipped = True \n",
    "      nb_very_bad+=1\n",
    "      # mauvaise lettre ou phoneme, pas la peine d'aller plus loi\n",
    "      # passer au mot suivant\n",
    "\n",
    "    # si la correspondance n'a pas été trouvé, tester si le mot est composé,\n",
    "    # et si oui, tester la correspondance de chaque partie (aka sous-mot)\n",
    "    if not is_ok and not is_skipped:    \n",
    "      graphemes = row['Mot'].lower().replace(',','')\n",
    "      phonemes = prononciation    \n",
    "      separateurs = [' ', '-']\n",
    "      for separateur in separateurs:\n",
    "        if separateur in graphemes[1:-1] :\n",
    "          mots_ = mot.split(separateur)\n",
    "          # si le mot n'est pas un mot composé, l'oubler, et passer à la suite\n",
    "          if len(mots_) <= 1:\n",
    "            continue\n",
    "          for mot_ in mots_:\n",
    "            try:\n",
    "              # récuperer le sous-mot identifiés ainsi que ses différentes prononciations possibles\n",
    "              phonemess_ = df[df.Mot==mot_]['Prononciation'].values\n",
    "              for phonemes_ in phonemess_:\n",
    "                graphemes_ = mot_\n",
    "                phonemes_ = phonemes_.replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "                is_ok_ = check_word_pronunciation(mot_, phonemes_, graphemes_, False, False, False, False)\n",
    "                if is_ok_:\n",
    "                    break                    \n",
    "              if is_ok_ == False:\n",
    "                is_ok = False                \n",
    "              else:\n",
    "                is_ok = True\n",
    "                break\n",
    "            except:\n",
    "              is_ok = False\n",
    "            \n",
    "    if is_ok and is_composé:\n",
    "        if not is_composé_direct:\n",
    "            nb_composés_indirects_found += 1\n",
    "    #if not is_ok and is_composé:\n",
    "    #    print('word=%s \\\\\\\\%s\\\\\\\\'% (mot, prononciation))\n",
    "        \n",
    "    if is_ok:\n",
    "      nb_samples_ok += 1\n",
    "      df2.at[index, 'Plausible']='oui'\n",
    "      indexes_to_forget.append(index)\n",
    "    else:\n",
    "      nb_samples_ko += 1\n",
    "      if verbose:\n",
    "        if row['Type'] != 'verbe_flexion':\n",
    "          print('word=%s \\\\\\\\%s\\\\\\\\'% (mot, prononciation))\n",
    "      df2.at[index, 'Plausible']='non'\n",
    "        \n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "durée = t1 - t0\n",
    "print('nb_samples:', nb_samples, ' durée de processing du dernier batch:', durée)\n",
    "      \n",
    "df2 = df2.drop(indexes_to_forget)\n",
    "\n",
    "if nb_samples > 0:\n",
    "  print('samples=%d, samples_ok=%d, samples_ko=%d, very_bad=%d, ok%%=%.2f' % \\\n",
    "        (nb_samples, nb_samples_ok, nb_samples_ko, nb_very_bad, \\\n",
    "         nb_samples_ok/nb_samples*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_samples: 1292602  durée de processing du dernier batch: 0:00:00.000838\n",
    "#samples=1292602, samples_ok=1279990, samples_ko=12612, very_bad=0 %ok=99.02\n",
    "\n",
    "#samples=1485362, samples_ok=1471019, samples_ko=14343, very_bad=0, ok%=99.03\n",
    "#nb_composés:160151\n",
    "#nb_composés_directs_found:154583\n",
    "#nb_composés_indirects_found:5216\n",
    "#nb_composés_not_found:352\n",
    "\n",
    "#samples=1485362, samples_ok=1468451, samples_ko=16911, very_bad=0, ok%=98.86\n",
    "#nb_composés:160151\n",
    "#nb_composés_directs_found:0\n",
    "#nb_composés_indirects_found:157231\n",
    "#nb_composés_not_found:2920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6X8pia-32RtQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7008"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nombre de mots dont la prononciation est détectée comme non plausible\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFgO0o3H4Srh",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audios</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "      <th>Plausible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1519864</th>\n",
       "      <td>TADs</td>\n",
       "      <td>te.a.de</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>T_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519908</th>\n",
       "      <td>TikTokeuse</td>\n",
       "      <td>tik.to.kœʁ</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>T_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519954</th>\n",
       "      <td>URNs</td>\n",
       "      <td>y.ɛʁ.ɛn</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>U_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519955</th>\n",
       "      <td>UpM</td>\n",
       "      <td>y.pe.em</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>U_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519966</th>\n",
       "      <td>Vosg’patt</td>\n",
       "      <td>voʒ.pat</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[\"LL-Q150 (fra)-Penegal-Vosg'patt.wav\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>V_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519967</th>\n",
       "      <td>WEIs</td>\n",
       "      <td>ˈwaj ou ˈwɛj</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>W_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519968</th>\n",
       "      <td>Wuchiaping’ien</td>\n",
       "      <td>wu.tʃja.piŋ.jɛ̃</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>W_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519970</th>\n",
       "      <td>XPs</td>\n",
       "      <td>iks.pe</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519972</th>\n",
       "      <td>Xi’an</td>\n",
       "      <td>sjan</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519973</th>\n",
       "      <td>Xi’an</td>\n",
       "      <td>ʃi.an</td>\n",
       "      <td>False</td>\n",
       "      <td>nom propre</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>X_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519977</th>\n",
       "      <td>YouTubeur</td>\n",
       "      <td>ju.tju.bœʁ</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519979</th>\n",
       "      <td>YouTubeurs</td>\n",
       "      <td>ju.tju.bœʁ</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519980</th>\n",
       "      <td>YouTubeuse</td>\n",
       "      <td>ju.tju.bøz</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519982</th>\n",
       "      <td>YouTubeuses</td>\n",
       "      <td>ju.tju.bøz</td>\n",
       "      <td>False</td>\n",
       "      <td>nom_flexion</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>Y_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520024</th>\n",
       "      <td>d’Ursel</td>\n",
       "      <td>dyʁs</td>\n",
       "      <td>False</td>\n",
       "      <td>nom de famille</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520041</th>\n",
       "      <td>raï'n'B</td>\n",
       "      <td>ʁaj.ɛn.bi</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_letters</td>\n",
       "      <td>'</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520045</th>\n",
       "      <td>éqCO₂</td>\n",
       "      <td>e.ki.va.lɑ̃ se.o.dø</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_letters</td>\n",
       "      <td>₂</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520046</th>\n",
       "      <td>€</td>\n",
       "      <td>ø.ʁo</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>€_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520047</th>\n",
       "      <td>℁</td>\n",
       "      <td>o bɔ̃ swɛ̃ də</td>\n",
       "      <td>False</td>\n",
       "      <td>préposition</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>℁_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520048</th>\n",
       "      <td>∴</td>\n",
       "      <td>mɔʁ‿o.vaʃ</td>\n",
       "      <td>False</td>\n",
       "      <td>symbole_num=2</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>err_lower_case</td>\n",
       "      <td>∴_as_first_letter</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mot        Prononciation  H_aspiré            Type  \\\n",
       "1519864            TADs              te.a.de     False     nom_flexion   \n",
       "1519908      TikTokeuse           tik.to.kœʁ     False             nom   \n",
       "1519954            URNs              y.ɛʁ.ɛn     False     nom_flexion   \n",
       "1519955             UpM              y.pe.em     False             nom   \n",
       "1519966       Vosg’patt              voʒ.pat     False             nom   \n",
       "1519967            WEIs         ˈwaj ou ˈwɛj     False     nom_flexion   \n",
       "1519968  Wuchiaping’ien      wu.tʃja.piŋ.jɛ̃     False             nom   \n",
       "1519970             XPs               iks.pe     False     nom_flexion   \n",
       "1519972           Xi’an                 sjan     False      nom propre   \n",
       "1519973           Xi’an                ʃi.an     False      nom propre   \n",
       "1519977       YouTubeur           ju.tju.bœʁ     False             nom   \n",
       "1519979      YouTubeurs           ju.tju.bœʁ     False     nom_flexion   \n",
       "1519980      YouTubeuse           ju.tju.bøz     False     nom_flexion   \n",
       "1519982     YouTubeuses           ju.tju.bøz     False     nom_flexion   \n",
       "1520024         d’Ursel                 dyʁs     False  nom de famille   \n",
       "1520041         raï'n'B            ʁaj.ɛn.bi     False             nom   \n",
       "1520045           éqCO₂  e.ki.va.lɑ̃ se.o.dø     False             nom   \n",
       "1520046               €                 ø.ʁo     False         symbole   \n",
       "1520047               ℁        o bɔ̃ swɛ̃ də     False     préposition   \n",
       "1520048               ∴            mɔʁ‿o.vaʃ     False   symbole_num=2   \n",
       "\n",
       "                                          Audios  Pré_valide       Warn_code  \\\n",
       "1519864                                       []       False  err_lower_case   \n",
       "1519908                                       []       False  err_lower_case   \n",
       "1519954                                       []       False  err_lower_case   \n",
       "1519955                                       []       False  err_lower_case   \n",
       "1519966  [\"LL-Q150 (fra)-Penegal-Vosg'patt.wav\"]       False  err_lower_case   \n",
       "1519967                                       []       False  err_lower_case   \n",
       "1519968                                       []       False  err_lower_case   \n",
       "1519970                                       []       False  err_lower_case   \n",
       "1519972                                       []       False  err_lower_case   \n",
       "1519973                                       []       False  err_lower_case   \n",
       "1519977                                       []       False  err_lower_case   \n",
       "1519979                                       []       False  err_lower_case   \n",
       "1519980                                       []       False  err_lower_case   \n",
       "1519982                                       []       False  err_lower_case   \n",
       "1520024                                       []        True               -   \n",
       "1520041                                       []       False     err_letters   \n",
       "1520045                                       []       False     err_letters   \n",
       "1520046                                       []       False  err_lower_case   \n",
       "1520047                                       []       False  err_lower_case   \n",
       "1520048                                       []       False  err_lower_case   \n",
       "\n",
       "                Warn_label Plausible  \n",
       "1519864  T_as_first_letter       non  \n",
       "1519908  T_as_first_letter       non  \n",
       "1519954  U_as_first_letter       non  \n",
       "1519955  U_as_first_letter       non  \n",
       "1519966  V_as_first_letter       non  \n",
       "1519967  W_as_first_letter       non  \n",
       "1519968  W_as_first_letter       non  \n",
       "1519970  X_as_first_letter       non  \n",
       "1519972  X_as_first_letter       non  \n",
       "1519973  X_as_first_letter       non  \n",
       "1519977  Y_as_first_letter       non  \n",
       "1519979  Y_as_first_letter       non  \n",
       "1519980  Y_as_first_letter       non  \n",
       "1519982  Y_as_first_letter       non  \n",
       "1520024                  -       non  \n",
       "1520041                  '       non  \n",
       "1520045                  ₂       non  \n",
       "1520046  €_as_first_letter       non  \n",
       "1520047  ℁_as_first_letter       non  \n",
       "1520048  ∴_as_first_letter       non  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 derniers mot dont la prononciation est détectée comme non plausible\n",
    "df2[df2.Plausible=='non'].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des résultats KO dans fichiers .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kq85BIVx4TCg"
   },
   "outputs": [],
   "source": [
    "# stockage des mots dot les prononciations sont non plausibles dans un fichier CSV\n",
    "df3 = df2.drop(columns=['Audios','H_aspiré','Pré_valide','Plausible'])\n",
    "df3.rename(columns = {'Err_Code':'Warn_Code', 'Err_Label':'Warn_Label'}, inplace = True)\n",
    "df3.to_csv(\"correspondances_non_trouvées.csv\", index=False, quotechar = '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stockage des mots dont les prononciations sont non plausibles \n",
    "df4 = \"'\" + df3.Mot + \"',\"\n",
    "df4.to_csv(\"mots_non_trouvés.csv\", index=False, quotechar = '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kG2E5cw6nfT9"
   },
   "source": [
    "### Test unitaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyMUWuQmd5Lk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNE\n",
      "nɔʁnɔʁɛst\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=0, grapheme_index=0,     phonemes_hist=[], graphemes_hist=[])\n",
      "### candidate current phonemes=% ['n', 'nɔʁ']\n",
      "trying candidate current phoneme=n\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0) current_phoneme:n\n",
      "current_phoneme:n\n",
      "phoneme \\n\\ matching graphemes [[n]] (last_graphemes:[[nne]])\n",
      "phoneme \\n\\ matching graphemes [[nn]] (last_graphemes:[[nne]])\n",
      "phoneme \\n\\ matching graphemes [[nne]] (last_graphemes:[[nne]])\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=1,     phonemes_hist=['n'], graphemes_hist=['n'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=1, grapheme_index=1) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[nn]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=2,     phonemes_hist=['n'], graphemes_hist=['nn'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=1, grapheme_index=2) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[nne]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=1, grapheme_index=3,     phonemes_hist=['n'], graphemes_hist=['nne'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\n\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=nɔʁ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=0, grapheme_index=0) current_phoneme:nɔʁ\n",
      "current_phoneme:nɔʁ\n",
      "phoneme \\nɔʁ\\ matching graphemes [[n]] (last_graphemes:[[nne]])\n",
      "trying2 current_phoneme \\nɔʁ\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=3, grapheme_index=1,     phonemes_hist=['nɔʁ'], graphemes_hist=['n'])\n",
      "### candidate current phonemes=% ['n', 'nɔʁ']\n",
      "trying candidate current phoneme=n\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1) current_phoneme:n\n",
      "current_phoneme:n\n",
      "phoneme \\n\\ matching graphemes [[n]] (last_graphemes:[[ne]])\n",
      "phoneme \\n\\ matching graphemes [[ne]] (last_graphemes:[[ne]])\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=4, grapheme_index=2,     phonemes_hist=['nɔʁ', 'n'], graphemes_hist=['n', 'n'])\n",
      "trying candidate current phoneme=ɔ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=4, grapheme_index=2) current_phoneme:ɔ\n",
      "current_phoneme:ɔ\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "trying2 current_phoneme \\n\\ and current_graphemes [[ne]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=4, grapheme_index=3,     phonemes_hist=['nɔʁ', 'n'], graphemes_hist=['n', 'ne'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\n\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=nɔʁ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=3, grapheme_index=1) current_phoneme:nɔʁ\n",
      "current_phoneme:nɔʁ\n",
      "phoneme \\nɔʁ\\ matching graphemes [[n]] (last_graphemes:[[ne]])\n",
      "trying2 current_phoneme \\nɔʁ\\ and current_graphemes [[n]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=6, grapheme_index=2,     phonemes_hist=['nɔʁ', 'nɔʁ'], graphemes_hist=['n', 'n'])\n",
      "### candidate current phonemes=% ['ɛ', 'ɛs', 'ɛst']\n",
      "trying candidate current phoneme=ɛ\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛ\n",
      "current_phoneme:ɛ\n",
      "phoneme \\ɛ\\ matching graphemes [[e]] (last_graphemes:[[e]])\n",
      "trying2 current_phoneme \\ɛ\\ and current_graphemes [[e]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=7, grapheme_index=3,     phonemes_hist=['nɔʁ', 'nɔʁ', 'ɛ'], graphemes_hist=['n', 'n', 'e'])\n",
      "ended ko\n",
      "LOST2 for current_phoneme \\ɛ\\ in process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2)\n",
      "move2 to next candidate phoneme\n",
      "trying candidate current phoneme=ɛs\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛs\n",
      "current_phoneme:ɛs\n",
      "KO0: phonemes=\\nɔʁnɔʁɛst\\ does not match any grapheme !!!\n",
      "move0 to next candidate phoneme\n",
      "trying candidate current phoneme=ɛst\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]], phoneme_index=6, grapheme_index=2) current_phoneme:ɛst\n",
      "current_phoneme:ɛst\n",
      "phoneme \\ɛst\\ matching graphemes [[e]] (last_graphemes:[[e]])\n",
      "trying2 current_phoneme \\ɛst\\ and current_graphemes [[e]]\n",
      "\n",
      "process_graphemes(phonemes=\\nɔʁnɔʁɛst\\, graphemes=[[nne]],     phoneme_index=9, grapheme_index=3,     phonemes_hist=['nɔʁ', 'nɔʁ', 'ɛst'], graphemes_hist=['n', 'n', 'e'])\n",
      "ended ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\ɛst\\ and current_graphemes [[e]] : worked ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\nɔʁ\\ and current_graphemes [[n]] : worked ok\n",
      "phonemes_hist2b: ['nɔʁ', 'nɔʁ', 'ɛst']\n",
      "graphemes_hist2b: ['n', 'n', 'e']\n",
      "current_phoneme \\nɔʁ\\ and current_graphemes [[n]] : worked ok\n",
      "NNE \\nɔʁnɔʁɛst\\ -> n,n,e \\nɔʁ,nɔʁ,ɛst\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mot et prononciation à tester unitairement\n",
    "graphemes_phonemes='SaturneXI,sa.tyʁnɔ̃z'\n",
    "graphemes_phonemes='SMSses,ɛs.ɛm.ɛs'\n",
    "graphemes_phonemes='NNE,nɔʁ nɔ.ʁ‿ɛst'\n",
    "\n",
    "# recharger la table de correspondance si nécessaire\n",
    "reload_table = False\n",
    "if reload_table:\n",
    "    phonemes2graphemes = read_table_de_correspondance()\n",
    "    phonemes2graphemes = add_keys(phonemes2graphemes)\n",
    "\n",
    "strings = graphemes_phonemes.split(',')\n",
    "mot = strings[0]\n",
    "graphemes = mot.lower()\n",
    "phonemes = strings[1].replace('(','').replace(')','').replace('‿','').replace('.','').replace(' ','')\n",
    "\n",
    "# nettoyage des strings\n",
    "#graphemes = graphemes.replace(' ','')\n",
    "#graphemes = graphemes.replace('-','')\n",
    "#graphemes = graphemes.replace(\"’\",'')\n",
    "phonemes = phonemes.replace(' ','')\n",
    "phonemes = phonemes.replace('\\\\','')\n",
    "phonemes = phonemes.replace('.','')\n",
    "phonemes = phonemes.replace('‿','')\n",
    "phonemes = phonemes.replace('(','')\n",
    "phonemes = phonemes.replace(')','')\n",
    "print(mot)\n",
    "print(phonemes)\n",
    "# test unitaire\n",
    "check_word_pronunciation(mot, phonemes, graphemes, unit_test=True, verbose0=True, verbose1=True, verbose2=True)\n",
    "#check_word_pronunciation(mot, phonemes, graphemes, unit_test=True, verbose0=False, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "th8Jvzrpk342"
   },
   "source": [
    "## Statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2laCDmzlJJO"
   },
   "outputs": [],
   "source": [
    "# Réaliser les comptages tottax statistiques sur les correspondances \n",
    "# précédemment comptées\n",
    "dfp = make_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBkvDJgyOlj4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>s</td>\n",
       "      <td>c’</td>\n",
       "      <td>178</td>\n",
       "      <td>0.00</td>\n",
       "      <td>c’</td>\n",
       "      <td>c’est</td>\n",
       "      <td>c’que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>s</td>\n",
       "      <td>s’</td>\n",
       "      <td>2973</td>\n",
       "      <td>0.00</td>\n",
       "      <td>s’abader</td>\n",
       "      <td>s’abaisser</td>\n",
       "      <td>s’abaisser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>s</td>\n",
       "      <td>ç’</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ç’</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>82964</td>\n",
       "      <td>0.12</td>\n",
       "      <td>abaciste</td>\n",
       "      <td>abacistes</td>\n",
       "      <td>abandogiciel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>s</td>\n",
       "      <td>ç</td>\n",
       "      <td>10850</td>\n",
       "      <td>0.01</td>\n",
       "      <td>accoinçon</td>\n",
       "      <td>accoinçons</td>\n",
       "      <td>agaça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>291222</td>\n",
       "      <td>0.44</td>\n",
       "      <td>aaronisme</td>\n",
       "      <td>aaronismes</td>\n",
       "      <td>aasax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>s</td>\n",
       "      <td>sc</td>\n",
       "      <td>5354</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abscise</td>\n",
       "      <td>abscises</td>\n",
       "      <td>abscision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>s</td>\n",
       "      <td>th</td>\n",
       "      <td>135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>chrestomathie</td>\n",
       "      <td>chrestomathies</td>\n",
       "      <td>classpath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>s</td>\n",
       "      <td>x</td>\n",
       "      <td>503</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antisoixantehuitard</td>\n",
       "      <td>antisoixantehuitards</td>\n",
       "      <td>auxerrois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>s</td>\n",
       "      <td>cc</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>accensa</td>\n",
       "      <td>accensai</td>\n",
       "      <td>accensaient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>s</td>\n",
       "      <td>ce</td>\n",
       "      <td>6288</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayance</td>\n",
       "      <td>aberrance</td>\n",
       "      <td>abjuratrice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>s</td>\n",
       "      <td>sç</td>\n",
       "      <td>112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesça</td>\n",
       "      <td>acquiesçable</td>\n",
       "      <td>acquiesçables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>s</td>\n",
       "      <td>se</td>\n",
       "      <td>1872</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaissemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>s</td>\n",
       "      <td>ss</td>\n",
       "      <td>120530</td>\n",
       "      <td>0.18</td>\n",
       "      <td>abadassiez</td>\n",
       "      <td>abadassions</td>\n",
       "      <td>abaissassiez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>s</td>\n",
       "      <td>sse</td>\n",
       "      <td>33030</td>\n",
       "      <td>0.05</td>\n",
       "      <td>abadasse</td>\n",
       "      <td>abaissasse</td>\n",
       "      <td>abalasse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>s</td>\n",
       "      <td>sth</td>\n",
       "      <td>97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatiques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>28258</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abaliénation</td>\n",
       "      <td>abaliénations</td>\n",
       "      <td>abannation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>s</td>\n",
       "      <td>z</td>\n",
       "      <td>453</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>s</td>\n",
       "      <td>cent</td>\n",
       "      <td>420</td>\n",
       "      <td>0.00</td>\n",
       "      <td>agacent</td>\n",
       "      <td>agencent</td>\n",
       "      <td>agoucent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>s</td>\n",
       "      <td>ces</td>\n",
       "      <td>3344</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayances</td>\n",
       "      <td>aberrances</td>\n",
       "      <td>abjuratrices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>s</td>\n",
       "      <td>sce</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesce</td>\n",
       "      <td>acquiescemens</td>\n",
       "      <td>acquiescement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>s</td>\n",
       "      <td>scent</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiescent</td>\n",
       "      <td>concupiscent</td>\n",
       "      <td>fascent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>s</td>\n",
       "      <td>sces</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesces</td>\n",
       "      <td>concupisces</td>\n",
       "      <td>drosces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>s</td>\n",
       "      <td>sent</td>\n",
       "      <td>355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaissent</td>\n",
       "      <td>absconsent</td>\n",
       "      <td>accensent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>s</td>\n",
       "      <td>ses</td>\n",
       "      <td>1110</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abbesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>s</td>\n",
       "      <td>ssent</td>\n",
       "      <td>29823</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadassent</td>\n",
       "      <td>abaissassent</td>\n",
       "      <td>abalassent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>s</td>\n",
       "      <td>sses</td>\n",
       "      <td>30240</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadasses</td>\n",
       "      <td>abaissasses</td>\n",
       "      <td>abalasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>s</td>\n",
       "      <td>ths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>classpaths</td>\n",
       "      <td>smithsonites</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>s</td>\n",
       "      <td>tz</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anetziens</td>\n",
       "      <td>trénitz</td>\n",
       "      <td>Anetz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage            exemple_1  \\\n",
       "249       s       c’         178         0.00                   c’   \n",
       "250       s       s’        2973         0.00             s’abader   \n",
       "251       s       ç’           1         0.00                   ç’   \n",
       "252       s        c       82964         0.12             abaciste   \n",
       "253       s        ç       10850         0.01            accoinçon   \n",
       "254       s        s      291222         0.44            aaronisme   \n",
       "255       s       sc        5354         0.00              abscise   \n",
       "256       s       th         135         0.00        chrestomathie   \n",
       "257       s        x         503         0.00  antisoixantehuitard   \n",
       "258       s       cc          52         0.00              accensa   \n",
       "259       s       ce        6288         0.00             abayance   \n",
       "260       s       sç         112         0.00            acquiesça   \n",
       "261       s       se        1872         0.00              abaisse   \n",
       "262       s       ss      120530         0.18           abadassiez   \n",
       "263       s      sse       33030         0.05             abadasse   \n",
       "264       s      sth          97         0.00      antiasthmatique   \n",
       "265       s        t       28258         0.04         abaliénation   \n",
       "266       s        z         453         0.00            abertzale   \n",
       "267       s     cent         420         0.00              agacent   \n",
       "268       s      ces        3344         0.00            abayances   \n",
       "269       s      sce          16         0.00            acquiesce   \n",
       "270       s    scent           7         0.00          acquiescent   \n",
       "271       s     sces          10         0.00           acquiesces   \n",
       "272       s     sent         355         0.00            abaissent   \n",
       "273       s      ses        1110         0.00             abaisses   \n",
       "274       s    ssent       29823         0.04           abadassent   \n",
       "275       s     sses       30240         0.04            abadasses   \n",
       "276       s      ths           2         0.00           classpaths   \n",
       "277       s       tz          12         0.00            anetziens   \n",
       "\n",
       "                exemple_2         exemple_3  \n",
       "249                 c’est             c’que  \n",
       "250            s’abaisser        s’abaisser  \n",
       "251                                          \n",
       "252             abacistes      abandogiciel  \n",
       "253            accoinçons             agaça  \n",
       "254            aaronismes             aasax  \n",
       "255              abscises         abscision  \n",
       "256        chrestomathies         classpath  \n",
       "257  antisoixantehuitards         auxerrois  \n",
       "258              accensai       accensaient  \n",
       "259             aberrance       abjuratrice  \n",
       "260          acquiesçable     acquiesçables  \n",
       "261               abaisse       abaissemens  \n",
       "262           abadassions      abaissassiez  \n",
       "263            abaissasse          abalasse  \n",
       "264       antiasthmatique  antiasthmatiques  \n",
       "265         abaliénations        abannation  \n",
       "266             abertzale        abertzales  \n",
       "267              agencent          agoucent  \n",
       "268            aberrances      abjuratrices  \n",
       "269         acquiescemens     acquiescement  \n",
       "270          concupiscent           fascent  \n",
       "271           concupisces           drosces  \n",
       "272            absconsent         accensent  \n",
       "273              abaisses          abbesses  \n",
       "274          abaissassent        abalassent  \n",
       "275           abaissasses         abalasses  \n",
       "276          smithsonites                    \n",
       "277               trénitz             Anetz  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les statistiques d'un phonème en particulier (ex: \\s\\)\n",
    "phoneme = 's'\n",
    "#hex(ord('s'))\n",
    "dfp[dfp.phonème == phoneme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvEujTABtn3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>s</td>\n",
       "      <td>c’</td>\n",
       "      <td>178</td>\n",
       "      <td>0.00</td>\n",
       "      <td>c’</td>\n",
       "      <td>c’est</td>\n",
       "      <td>c’que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>s</td>\n",
       "      <td>s’</td>\n",
       "      <td>2973</td>\n",
       "      <td>0.00</td>\n",
       "      <td>s’abader</td>\n",
       "      <td>s’abaisser</td>\n",
       "      <td>s’abaisser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>s</td>\n",
       "      <td>ç’</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ç’</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>82964</td>\n",
       "      <td>0.12</td>\n",
       "      <td>abaciste</td>\n",
       "      <td>abacistes</td>\n",
       "      <td>abandogiciel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>s</td>\n",
       "      <td>ç</td>\n",
       "      <td>10850</td>\n",
       "      <td>0.01</td>\n",
       "      <td>accoinçon</td>\n",
       "      <td>accoinçons</td>\n",
       "      <td>agaça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>291222</td>\n",
       "      <td>0.44</td>\n",
       "      <td>aaronisme</td>\n",
       "      <td>aaronismes</td>\n",
       "      <td>aasax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>s</td>\n",
       "      <td>sc</td>\n",
       "      <td>5354</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abscise</td>\n",
       "      <td>abscises</td>\n",
       "      <td>abscision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>s</td>\n",
       "      <td>th</td>\n",
       "      <td>135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>chrestomathie</td>\n",
       "      <td>chrestomathies</td>\n",
       "      <td>classpath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>s</td>\n",
       "      <td>x</td>\n",
       "      <td>503</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antisoixantehuitard</td>\n",
       "      <td>antisoixantehuitards</td>\n",
       "      <td>auxerrois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>s</td>\n",
       "      <td>cc</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>accensa</td>\n",
       "      <td>accensai</td>\n",
       "      <td>accensaient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>s</td>\n",
       "      <td>ce</td>\n",
       "      <td>6288</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayance</td>\n",
       "      <td>aberrance</td>\n",
       "      <td>abjuratrice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>s</td>\n",
       "      <td>sç</td>\n",
       "      <td>112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesça</td>\n",
       "      <td>acquiesçable</td>\n",
       "      <td>acquiesçables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>s</td>\n",
       "      <td>se</td>\n",
       "      <td>1872</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>abaissemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>s</td>\n",
       "      <td>ss</td>\n",
       "      <td>120530</td>\n",
       "      <td>0.18</td>\n",
       "      <td>abadassiez</td>\n",
       "      <td>abadassions</td>\n",
       "      <td>abaissassiez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>s</td>\n",
       "      <td>sse</td>\n",
       "      <td>33030</td>\n",
       "      <td>0.05</td>\n",
       "      <td>abadasse</td>\n",
       "      <td>abaissasse</td>\n",
       "      <td>abalasse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>s</td>\n",
       "      <td>sth</td>\n",
       "      <td>97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatique</td>\n",
       "      <td>antiasthmatiques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>28258</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abaliénation</td>\n",
       "      <td>abaliénations</td>\n",
       "      <td>abannation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>s</td>\n",
       "      <td>z</td>\n",
       "      <td>453</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzale</td>\n",
       "      <td>abertzales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>s</td>\n",
       "      <td>cent</td>\n",
       "      <td>420</td>\n",
       "      <td>0.00</td>\n",
       "      <td>agacent</td>\n",
       "      <td>agencent</td>\n",
       "      <td>agoucent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>s</td>\n",
       "      <td>ces</td>\n",
       "      <td>3344</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abayances</td>\n",
       "      <td>aberrances</td>\n",
       "      <td>abjuratrices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>s</td>\n",
       "      <td>sce</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesce</td>\n",
       "      <td>acquiescemens</td>\n",
       "      <td>acquiescement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>s</td>\n",
       "      <td>scent</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiescent</td>\n",
       "      <td>concupiscent</td>\n",
       "      <td>fascent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>s</td>\n",
       "      <td>sces</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acquiesces</td>\n",
       "      <td>concupisces</td>\n",
       "      <td>drosces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>s</td>\n",
       "      <td>sent</td>\n",
       "      <td>355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaissent</td>\n",
       "      <td>absconsent</td>\n",
       "      <td>accensent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>s</td>\n",
       "      <td>ses</td>\n",
       "      <td>1110</td>\n",
       "      <td>0.00</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abaisses</td>\n",
       "      <td>abbesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>s</td>\n",
       "      <td>ssent</td>\n",
       "      <td>29823</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadassent</td>\n",
       "      <td>abaissassent</td>\n",
       "      <td>abalassent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>s</td>\n",
       "      <td>sses</td>\n",
       "      <td>30240</td>\n",
       "      <td>0.04</td>\n",
       "      <td>abadasses</td>\n",
       "      <td>abaissasses</td>\n",
       "      <td>abalasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>s</td>\n",
       "      <td>ths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>classpaths</td>\n",
       "      <td>smithsonites</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>s</td>\n",
       "      <td>tz</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anetziens</td>\n",
       "      <td>trénitz</td>\n",
       "      <td>Anetz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage            exemple_1  \\\n",
       "249       s       c’         178         0.00                   c’   \n",
       "250       s       s’        2973         0.00             s’abader   \n",
       "251       s       ç’           1         0.00                   ç’   \n",
       "252       s        c       82964         0.12             abaciste   \n",
       "253       s        ç       10850         0.01            accoinçon   \n",
       "254       s        s      291222         0.44            aaronisme   \n",
       "255       s       sc        5354         0.00              abscise   \n",
       "256       s       th         135         0.00        chrestomathie   \n",
       "257       s        x         503         0.00  antisoixantehuitard   \n",
       "258       s       cc          52         0.00              accensa   \n",
       "259       s       ce        6288         0.00             abayance   \n",
       "260       s       sç         112         0.00            acquiesça   \n",
       "261       s       se        1872         0.00              abaisse   \n",
       "262       s       ss      120530         0.18           abadassiez   \n",
       "263       s      sse       33030         0.05             abadasse   \n",
       "264       s      sth          97         0.00      antiasthmatique   \n",
       "265       s        t       28258         0.04         abaliénation   \n",
       "266       s        z         453         0.00            abertzale   \n",
       "267       s     cent         420         0.00              agacent   \n",
       "268       s      ces        3344         0.00            abayances   \n",
       "269       s      sce          16         0.00            acquiesce   \n",
       "270       s    scent           7         0.00          acquiescent   \n",
       "271       s     sces          10         0.00           acquiesces   \n",
       "272       s     sent         355         0.00            abaissent   \n",
       "273       s      ses        1110         0.00             abaisses   \n",
       "274       s    ssent       29823         0.04           abadassent   \n",
       "275       s     sses       30240         0.04            abadasses   \n",
       "276       s      ths           2         0.00           classpaths   \n",
       "277       s       tz          12         0.00            anetziens   \n",
       "\n",
       "                exemple_2         exemple_3  \n",
       "249                 c’est             c’que  \n",
       "250            s’abaisser        s’abaisser  \n",
       "251                                          \n",
       "252             abacistes      abandogiciel  \n",
       "253            accoinçons             agaça  \n",
       "254            aaronismes             aasax  \n",
       "255              abscises         abscision  \n",
       "256        chrestomathies         classpath  \n",
       "257  antisoixantehuitards         auxerrois  \n",
       "258              accensai       accensaient  \n",
       "259             aberrance       abjuratrice  \n",
       "260          acquiesçable     acquiesçables  \n",
       "261               abaisse       abaissemens  \n",
       "262           abadassions      abaissassiez  \n",
       "263            abaissasse          abalasse  \n",
       "264       antiasthmatique  antiasthmatiques  \n",
       "265         abaliénations        abannation  \n",
       "266             abertzale        abertzales  \n",
       "267              agencent          agoucent  \n",
       "268            aberrances      abjuratrices  \n",
       "269         acquiescemens     acquiescement  \n",
       "270          concupiscent           fascent  \n",
       "271           concupisces           drosces  \n",
       "272            absconsent         accensent  \n",
       "273              abaisses          abbesses  \n",
       "274          abaissassent        abalassent  \n",
       "275           abaissasses         abalasses  \n",
       "276          smithsonites                    \n",
       "277               trénitz             Anetz  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp[dfp.phonème == phoneme]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTLaTRWYJn2r"
   },
   "source": [
    "## Bilan des correspondances non trouvées\n",
    "\n",
    "* Normalement, aucune ligne ne devrait être affichée (si noms communs, noms propres et sigles analysés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Df8fmZunHd7r"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonème</th>\n",
       "      <th>graphème</th>\n",
       "      <th>occurences</th>\n",
       "      <th>pourcentage</th>\n",
       "      <th>exemple_1</th>\n",
       "      <th>exemple_2</th>\n",
       "      <th>exemple_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>ɥ</td>\n",
       "      <td>’hu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>ɛ</td>\n",
       "      <td>eighs</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>œ̃</td>\n",
       "      <td>Hun</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>œ̃</td>\n",
       "      <td>Huns</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>œ</td>\n",
       "      <td>ogl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ø</td>\n",
       "      <td>hœ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>ø</td>\n",
       "      <td>euent</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>o</td>\n",
       "      <td>hoa</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>ɑ̃</td>\n",
       "      <td>aën</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>a</td>\n",
       "      <td>acts</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>aj</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>aj</td>\n",
       "      <td>igh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ɡz</td>\n",
       "      <td>xh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>ɔɛ</td>\n",
       "      <td>œ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>tʃ</td>\n",
       "      <td>ch</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>tʃ</td>\n",
       "      <td>œ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phonème graphème  occurences  pourcentage exemple_1 exemple_2 exemple_3\n",
       "380       ɥ      ’hu           0          0.0                              \n",
       "532       ɛ    eighs           0          0.0                              \n",
       "584      œ̃      Hun           0          0.0                              \n",
       "585      œ̃     Huns           0          0.0                              \n",
       "605       œ      ogl           0          0.0                              \n",
       "619       ø       hœ           0          0.0                              \n",
       "627       ø    euent           0          0.0                              \n",
       "747       o      hoa           0          0.0                              \n",
       "846      ɑ̃      aën           0          0.0                              \n",
       "916       a     acts           0          0.0                              \n",
       "944      aj        j           0          0.0                              \n",
       "945      aj      igh           0          0.0                              \n",
       "958      ɡz       xh           0          0.0                              \n",
       "959      ɔɛ        œ           0          0.0                              \n",
       "960      tʃ       ch           0          0.0                              \n",
       "962      tʃ        œ           0          0.0                              "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "dfp[dfp.occurences == 0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test_de_plausibité.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
